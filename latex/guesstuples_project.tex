\documentclass[12pt]{article}

\input{guesstuples_preamble}

%opening
\title{GuessTuples Project}
\author{Andrew J. Wren}

\begin{document}

\maketitle

\begin{abstract}
	Notes on \texttt{GuessTuples} project aka \texttt{NLearn}
\end{abstract}


\section{Configuring the nets}

\subsection{Alice}

{\bf One per bit.} The input array to guess is $\vec{x}=(x_j)_{j=0,...,N_\text{elements}}.$  There should be $N_\text{code}$ outputs taking values $\vec{y} = (y_j)_{j=0,...,N_\text{code}}.$

Normalise all the rewards so that for each bit $j,$ $\rt{j} + \left(N_\text{code} - 1\right)\rf{j} = 0.$  In other words
\begin{equation}
	r_{jk}
	\gets
	r_{jk} - \frac{ \rt{j} + \left(N_\text{code} - 1\right)\rf{j}}{N_\text{code}}
	.
\end{equation}

The $Q$ estimate is then taken to be
\begin{equation}
	Q(\vec{x})
	=
	\sum_j b_j y_j
	\equiv
	\sum_j \abs{y_j}
	,		
\end{equation}
where
\begin{equation}
	b_j = \operatorname{sgn} (y_j)
\end{equation}
is the prediction for the machine value of the $j$th bit.  The loss function is
\begin{equation}
	L
	=
	\abs{Q(\vec{x}) -r}^2
	. 
\end{equation}

Alternative approaches include:
\begin{enumerate}
	\item Two outputs for each bit showing the reward for each of $0$ and $1.$  {\em May reflect negative rewards better?}
	
	\item Combine the rewards from the bits (with either one or two outputs per bit) by something other than addition - e.g. multiplication or via an NN. {\em The NN option seems quite interesting.  Interesting to use \verb|pytorch|'s gradients for that.}
	
	\item {\bf One per code.} One output for each possible code. {\em Might work but $2^{N_\text{code}}$ is quite large... not impossibly so if $N_\text{code}=8.$}
	
	\item Inspired by \rcite{he2015deep}, feed $\x$ into Alice's 'first' net, to get output $\y,$ and all possible codes $\c$ into her 'second' net, both net's having the same target dimensionality (a hyperparameter).  Then the code to use is the one $\c(\x)$ closest to the output of the first net, with the $Q$ being given by the inner product $Q = \left\langle \y, \c(\x) \right\rangle.$  \rcite{dulac2015deep} might provide an alternative, actor--critic, approach on a similar theme.  The main case above is, in effect, an embedding of $\x$ into the target space (of dimensionality $N_\text{code}$) which then compares with the natural embedding of $\c$ by, in effect, the inner product.
	
	\item \rcite{majeed2020exact} suggest sequentialising, which points to a variant of our main approach which does each bit in succession and feeding those results into successive Alice--nets so the $Q$-estimate for later bits takes account of earlier bits / estimates, with the $N_\text{code}$th estimate providing a final code $\c$ and $Q$-estimate for that code.
	
	\item Move away from typical Q-learning.  Instead Alice's output is the code $\vec{c}$ and then when Bob makes his choice $\vec{x}_\text{pred}$ (see below) run that choice through a copy of Alice, to get $\vec{c}_\text{Bob}$ and then the loss function is
	\begin{equation}
		L
		=
		-\,
		r(\vec{c}, \vec{c}_\text{Bob})
		.
	\end{equation}
\end{enumerate}

\subsection{Bob}

{\bf One per bit} aka {\bf Simple.}  Bob receives a matrix, $\mat{X} = (\vec{X}_{i}) = (X_{ij})$ for $0\leq i < N_\text{select},\ 0\leq j < N_\text{elements},$ and a code $\vec{c}=(c_k)_{k=0,...,N_\text{code}}.$  Why not makes his outputs be $Q$-estimates $\vec{z} = (z_i)_{i=0,...,N_\text{select}}.$ Bob's prediction is then
$
	\vec{x}_\text{pred}
=
\vec{X}_{i_\text{pred}}
$
where
\begin{equation}
	i_\text{pred}
	=
	\operatorname{argmax}_{i}  (z_i)
	.
\end{equation}
The loss function is 
\begin{equation}	\label{eq:Bob_loss_fn}
	L
	=
	\abs{\vec{z}_{i_\text{pred}} -r}^2
	. 
\end{equation}

How do we enforce covariance with respect to the order of $(\vec{X}_{i})$?
\begin{enumerate}
	\item Covariance will occur naturally and quickly without any specific intervention.  {\em To be determined.}
	\item Covariance can be enforced through choosing a set $\left\lbrace \sigma \right\rbrace \subseteq S_{n_\text{code}},$ which could be generated element--by--element by composing randomly--selected basis transpositions $(j\ j+1),$ and then adding to the loss a term
	\begin{equation}
		\mu\sum_\sigma\abs{\vec{z} - \sigma^{-1}\left[\vec{z}(\sigma[\mat{X}])\right]}^2
	\end{equation}
	for some fixed hyperparameter $\mu > 0.$  Note this the term is still run backward through the original $\vec{x}\mapsto\vec{z}$ net configuration only.  {\em How effective would that be?  How big does $\left\lbrace \sigma \right\rbrace$ have to be? And how much time would the permutation and the additions forward passes cost?}
	\item Enforce covariance via direct identification of weights in Bob's net.  {\em How?}
	\item Something related to set transformers. {\em ?}
	\item Adopt a different basic set--up where each $(X_i)$ is fed through the net separately, alongside the code $\vec{c},$ resulting in a $Q$-estimate $\vec{z}_i.$  Then find the loss function as in \eref{eq:Bob_loss_fn}.  {\em Seems the most straightforward?}
\end{enumerate}
None of these quite amount to Bob seeks to reproduce the Alice's code vocabulary.  However Bob could additionally set up a net in the same basic configuration as Alice's (he doesn't know the weights of course) and train {\em that} net jointly with his main net.


\section{Results}

\subsection{Original strategies}

\fref{fig:fig-oneperbitsqrtlosses} is representative of the better results for the original strategies, {\bf one per bit} --- in other words, not very good.\footnote{The plot is taken from TensorBoard which gives an \texttt{.svg} file, then converted to \texttt{.pdf} by \texttt{rsvg-convert -f pdf -o <{\em fig-file-name}>.pdf "Sqrt losses.svg"}.}  Increasing from \verb|h.GAMESIZE = 1| to \verb|h.GAMESIZE = 32| gives no better results.
\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{fig-one_per_bit_sqrt_losses}
	\caption{The best results --- from \texttt{/runs/Apr27\_23-01-58\_andrew-XPS-15-9570}. The lines show the square root of the mean square losses with (a) \texttt{lr=0.3} Alice (orange), Bob (dark blue); (b) \texttt{lr=0.1} Alice (brick red), Bob (cyan); (c) \texttt{lr=0.01} Alice (pink), Bob (green).  The plot is from TensorFlow and uses smoothing of 0.999.}
	\label{fig:fig-oneperbitsqrtlosses}
\end{figure}

\section{Revised approach --- \texttt{NLearn}}

Key runs:  
\begin{enumerate}
	\item \verb|21-05-01_12:05:16| is the strategy that works 
	\begin{lstlisting}
		'ALICE_STRATEGY': 'from_decisions',
		'BOB_STRATEGY': 'circular_vocab'
	\end{lstlisting}
	up to a point when it levels off.  Gets to $\verb|reward|=0.6$.
	
	\item  \verb|21-05-01_20:04:35| other \verb|lr| choices but same result.	
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{Fig_Mean_Rewards_21-05-01_20:04:35}
		\caption{Mean Rewards per game for \texttt{21-05-01\_20:04:35}.  By colour, (Alice \texttt{lr}, Bob \texttt{lr}) are: cyan $(0.1, 0.1),$ orange $(0.1, 0.01),$ pink $(0.01, 0.1),$ and blue $(0.01, 0.01).$}
		\label{fig:figmeanrewards21-05-01200435}
	\end{figure}

	\item \verb|21-05-02_17:29:40| stops Alice training at some point. Alice $\verb|lr|=0.1$ and Bob $\verb|lr|=0.01$ gets to $0.78.$
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{Fig_Mean_Rewards_21-05-02_17:29:40}
		\caption{Mean Rewards per game for \texttt{21-05-02\_17:29:40}.  By colour, (Alice \texttt{lr}, Bob \texttt{lr}) are: green $(0.1, 0.1),$ orange $(0.1, 0.01),$ grey $(0.01, 0.1),$ and cyan $(0.01, 0.01).$}
		\label{fig:figmeanrewards21-05-02172940}
	\end{figure}
	The \verb|config| includes
	\begin{lstlisting}
		hyperparameters = {
			'N_ITERATIONS': 500000,
			'RANDOM_SEED': 42,
			'TORCH_RANDOM_SEED': 4242,
			'ALICE_LAYERS': 3,
			'ALICE_WIDTH': 50,
			'BOB_LAYERS': 3,
			'BOB_WIDTH': 50,
			'BATCHSIZE': 32,
			'GAMESIZE': 32,
			'BUFFER_CAPACITY': 640000,
			'START_TRAINING': 20000,
			'N_SELECT': 5,
			'EPSILON_ONE_END': 40000,
			'EPSILON_MIN': 0.01,
			'EPSILON_MIN_POINT': 300000,
			'ALICE_STRATEGY': 'from_decisions',
			'BOB_STRATEGY': 'circular_vocab',
			'ALICE_OPTIMIZER': ('SGD', '{"lr": 0.1}'),
			'BOB_OPTIMIZER': ('SGD', '{"lr": 0.01}'),
			'ALICE_LOSS_FUNCTION': ('MSE', {}),
			'BOB_LOSS_FUNCTION': 'Same',
			'ALICE_LAST_TRAINING': 200000
	\end{lstlisting}
\end{enumerate}

Things to try:
\begin{enumerate}
	\item What codes does best Alice generate?
	
	\item Try using the loss function to constraint outputs to nearer bit values.
	
	\item How quickly can \verb|epsilon| be tapered? 
	
	\item Vary learning rates.
	
	\item Vary \verb|modulus|, \verb|N_CODE| and \verb|N_SELECT|.
	
	\item Introduce noise.
	
	\item Alice strategy with a code, as input and the output are values for the numbers.  In each play (or train?) step feed all the codes in and the outputs indicate how well represents each number???
	
	\item Try best strategy but with Alice outputs having dimension \verb|2 ** N_CODE|.
	
	\item Train bits successively. 
	
	\item Look at MARL literature.
\end{enumerate}

The best Alice so far, \verb|21-05-02_17:29:40 hp_run=2| generates codes as follows:
\begin{lstlisting}
	11101100	[0, 1, 2, 12, 13, 14, 15]
	11101110	[3]
	10101110	[4, 6]
	10100110	[5, 7]
	10100100	[8]
	11100100	[9, 10, 11]
\end{lstlisting}
Surprisingly only six distinct codes used!  At least the first and last have sequential runs of numbers.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{JHEP}
\bibliography{guesstuples_project}

\end{document}

