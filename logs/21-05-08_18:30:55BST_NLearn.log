The closed log for run 21-05-08_18:30:55BST

TUPLE_SPEC = ((16,),)
N_CODE = 8
SMOOTHING_LENGTH = 10000
SAVE_PERIOD = 100000
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Used: "cuda"
MODEL_FOLDER = 'models'
CONFIGS_FOLDER = 'configs'
LOGS_FOLDER = 'logs'

hyperparameters = {
	'N_ITERATIONS': 70000,
	'RANDOM_SEEDS': [(14223, 244096, 596642, 487871)],
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_LAYERS': 3,
	'BOB_WIDTH': 50,
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 2000,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 20000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_STRATEGY': 'circular_vocab',
	'ALICE_OPTIMIZER': ['SGD(lr=0.01)'],
	'BOB_OPTIMIZER': [('SGD', '{"lr": 0.01}')],
	'ALICE_LOSS_FUNCTION': ['Huber(beta=0.1)'],
	'BOB_LOSS_FUNCTION': ('torch.nn.MSE', {}),
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': [0, 0.1, 0.2, 0.3],
	'ALICE_DOUBLE': 500
}



>>>> hp_run=1 of 4
hyperparameters = {
	'N_ITERATIONS': 70000,
	'RANDOM_SEEDS': (14223, 244096, 596642, 487871),
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_LAYERS': 3,
	'BOB_WIDTH': 50,
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 2000,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 20000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_STRATEGY': 'circular_vocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': ('SGD', '{"lr": 0.01}'),
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': ('torch.nn.MSE', {}),
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0,
	'ALICE_DOUBLE': 500
}

tuple_specs.random_reward_sd()=0.7071067811865476

Iteration=     20000 training nets give:
alice_loss.item()=0.4816061556339264	bob_loss.item()=0.4434467554092407

00010111	[0, 1, 12, 13, 14, 15]
10011110	[2, 3, 4]
10100100	[5, 6, 7, 8]
10010000	[9, 10, 11]

00010111	6	False
10011110	6	False
10100100	8	True
10010000	9	True

Number of codes used=4

Iteration=     30000 training nets give:
alice_loss.item()=0.2061357945203781	bob_loss.item()=0.13024330139160156

11011111	[0, 1, 2, 14, 15]
10011110	[3, 4, 5, 6]
10100100	[7, 8]
10010000	[9, 10]
11000010	[11, 12, 13]

11011111	15	True
10011110	4	True
10100100	7	True
10010000	10	True
11000010	13	True

Number of codes used=5

Iteration=     40000 training nets give:
alice_loss.item()=0.04990670830011368	bob_loss.item()=0.026096679270267487

11011111	[0, 1, 14, 15]
11011101	[2]
10011110	[3, 4, 5]
10100100	[6, 7, 8]
10010000	[9, 10, 11]
11000010	[12, 13]

11011111	15	True
11011101	15	False
10011110	4	True
10100100	7	True
10010000	10	True
11000010	13	True

Number of codes used=6

Iteration=     50000 training nets give:
alice_loss.item()=7.294834358617663e-05	bob_loss.item()=0.01595449075102806

11011111	[0, 1, 14, 15]
11011101	[2]
10011110	[3, 4, 5]
10100100	[6, 7, 8]
10010000	[9, 10, 11]
11000010	[12, 13]

11011111	15	True
11011101	15	False
10011110	4	True
10100100	7	True
10010000	10	True
11000010	13	True

Number of codes used=6

Iteration=     60000 training nets give:
alice_loss.item()=1.5314145684897085e-07	bob_loss.item()=0.004845735616981983

11011111	[0, 1, 14, 15]
11011101	[2]
10011110	[3, 4, 5]
10100100	[6, 7, 8]
10010000	[9, 10, 11]
11000010	[12, 13]

11011111	15	True
11011101	15	False
10011110	4	True
10100100	7	True
10010000	10	True
11000010	13	True

Number of codes used=6

Iteration=     70000 training nets give:
alice_loss.item()=2.653433028854124e-13	bob_loss.item()=0.0035796999000012875

11011111	[0, 1, 2, 14, 15]
10011110	[3, 4, 5]
10100100	[6, 7, 8]
10010000	[9, 10, 11]
11000010	[12, 13]

11011111	15	True
10011110	4	True
10100100	7	True
10010000	10	True
11000010	13	True

Number of codes used=5



>>>> hp_run=2 of 4, time elapsed 0:20:16 of estimated 1:21:04, 
implying ending at 19:52:00BST on Saturday 8 May 2021
hyperparameters = {
	'N_ITERATIONS': 70000,
	'RANDOM_SEEDS': (14223, 244096, 596642, 487871),
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_LAYERS': 3,
	'BOB_WIDTH': 50,
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 2000,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 20000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_STRATEGY': 'circular_vocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': ('SGD', '{"lr": 0.01}'),
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': ('torch.nn.MSE', {}),
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0.1,
	'ALICE_DOUBLE': 500
}

tuple_specs.random_reward_sd()=0.7071067811865476

Iteration=     20000 training nets give:
alice_loss.item()=0.7030644416809082	bob_loss.item()=0.4984700381755829

00000101	[0, 8, 9, 10, 11, 12, 13, 14, 15]
10101110	[1, 2, 3]
10011001	[4, 5, 6, 7]

00000101	0	True
10101110	12	False
10011001	14	False

Number of codes used=3

Iteration=     30000 training nets give:
alice_loss.item()=0.2839583158493042	bob_loss.item()=0.28632843494415283

00000101	[0, 14, 15]
00001100	[1, 2, 3, 4, 5]
10100100	[6, 7, 8]
01110100	[9, 10, 11, 12, 13]

00000101	13	False
00001100	3	True
10100100	7	True
01110100	11	True

Number of codes used=4

Iteration=     40000 training nets give:
alice_loss.item()=0.10327430814504623	bob_loss.item()=0.08844482898712158

00000100	[0, 15]
01001100	[1, 2]
00001100	[3]
10001100	[4, 5]
10100110	[6]
10100100	[7]
10100000	[8]
01110000	[9]
01010100	[10]
01110100	[11]
01001110	[12]
01000101	[13]
10000101	[14]

00000100	0	True
01001100	2	True
00001100	2	False
10001100	4	True
10100110	7	False
10100100	6	False
10100000	8	True
01110000	10	False
01010100	11	False
01110100	11	True
01001110	1	False
01000101	13	True
10000101	15	False

Number of codes used=13

Iteration=     50000 training nets give:
alice_loss.item()=0.09334342926740646	bob_loss.item()=0.1634792685508728

00000100	[0]
00011100	[1]
01001100	[2]
00001110	[3]
10001100	[4]
00101100	[5]
10000000	[6]
00100100	[7]
10110100	[8]
11110000	[9]
01110010	[10]
01110100	[11]
01100111	[12]
01100101	[13]
00011101	[14]
11000101	[15]

00000100	0	True
00011100	1	True
01001100	2	True
00001110	3	True
10001100	4	True
00101100	5	True
10000000	6	True
00100100	7	True
10110100	8	True
11110000	9	True
01110010	10	True
01110100	11	True
01100111	13	False
01100101	13	True
00011101	15	False
11000101	15	True

Number of codes used=16

Iteration=     60000 training nets give:
alice_loss.item()=0.018818557262420654	bob_loss.item()=0.041576091200113297

00000100	[0]
00011100	[1]
01001100	[2]
00001110	[3]
10001100	[4]
10101100	[5]
10000000	[6]
10010100	[7]
00100010	[8]
11110100	[9]
01110010	[10]
01110100	[11]
00100101	[12]
01100101	[13]
00000101	[14]
00000000	[15]

00000100	0	True
00011100	1	True
01001100	2	True
00001110	3	True
10001100	4	True
10101100	5	True
10000000	6	True
10010100	7	True
00100010	8	True
11110100	9	True
01110010	10	True
01110100	11	True
00100101	12	True
01100101	13	True
00000101	14	True
00000000	15	True

Number of codes used=16

Iteration=     70000 training nets give:
alice_loss.item()=8.184563193935901e-05	bob_loss.item()=0.0032401883509010077

00000100	[0]
01000100	[1]
01001100	[2]
00001110	[3]
10001100	[4]
00101100	[5]
10000000	[6]
00100100	[7]
10100000	[8]
11110000	[9]
01010010	[10]
01110100	[11]
00100101	[12]
11000001	[13]
00000101	[14]
10000101	[15]

00000100	0	True
01000100	1	True
01001100	2	True
00001110	3	True
10001100	4	True
00101100	5	True
10000000	6	True
00100100	7	True
10100000	8	True
11110000	9	True
01010010	10	True
01110100	11	True
00100101	12	True
11000001	13	True
00000101	14	True
10000101	15	True

Number of codes used=16



>>>> hp_run=3 of 4, time elapsed 0:41:33 of estimated 1:23:07, 
implying ending at 19:54:03BST on Saturday 8 May 2021
hyperparameters = {
	'N_ITERATIONS': 70000,
	'RANDOM_SEEDS': (14223, 244096, 596642, 487871),
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_LAYERS': 3,
	'BOB_WIDTH': 50,
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 2000,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 20000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_STRATEGY': 'circular_vocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': ('SGD', '{"lr": 0.01}'),
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': ('torch.nn.MSE', {}),
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0.2,
	'ALICE_DOUBLE': 500
}

tuple_specs.random_reward_sd()=0.7071067811865476

Iteration=     20000 training nets give:
alice_loss.item()=0.5066977143287659	bob_loss.item()=0.503874659538269

01011000	[0, 13, 14, 15]
11110111	[1, 2, 3, 4, 5, 6, 7]
01110101	[8, 9, 10]
00010110	[11, 12]

01011000	0	True
11110111	1	True
01110101	1	False
00010110	5	False

Number of codes used=4

Iteration=     30000 training nets give:
alice_loss.item()=0.16015900671482086	bob_loss.item()=0.26663216948509216

01011000	[0, 1, 15]
11110111	[2, 3, 4]
01110111	[5, 6, 7]
01100110	[8, 9, 10]
01010110	[11, 12, 13, 14]

01011000	0	True
11110111	4	True
01110111	8	False
01100110	10	True
01010110	12	True

Number of codes used=5

Iteration=     40000 training nets give:
alice_loss.item()=0.1497730314731598	bob_loss.item()=0.30470606684684753

01000000	[0]
10111111	[1, 2]
11111111	[3]
11110110	[4]
11110101	[5]
01000010	[6]
01110111	[7]
01110011	[8]
10110001	[9, 10, 11]
01010110	[12]
00010010	[13, 14]
01011010	[15]

01000000	13	False
10111111	4	False
11111111	3	True
11110110	4	True
11110101	4	False
01000010	11	False
01110111	8	False
01110011	7	False
10110001	4	False
01010110	12	True
00010010	12	False
01011010	15	True

Number of codes used=12

Iteration=     50000 training nets give:
alice_loss.item()=0.1166786178946495	bob_loss.item()=0.17175474762916565

01111010	[0]
11011000	[1, 2]
11110111	[3]
11110001	[4]
00100001	[5]
01100011	[6]
01110011	[7]
00100111	[8]
01101010	[9]
01101110	[10]
01000010	[11]
00010010	[12]
01010100	[13]
00011110	[14]
01011111	[15]

01111010	0	True
11011000	1	True
11110111	4	False
11110001	4	True
00100001	6	False
01100011	7	False
01110011	6	False
00100111	8	True
01101010	9	True
01101110	10	True
01000010	11	True
00010010	12	True
01010100	13	True
00011110	14	True
01011111	14	False

Number of codes used=15

Iteration=     60000 training nets give:
alice_loss.item()=0.03287773206830025	bob_loss.item()=0.12138126790523529

01001000	[0]
10000000	[1]
01111001	[2]
11011111	[3]
11101101	[4]
11100011	[5]
01100001	[6]
00110101	[7]
00010011	[8]
01110110	[9]
01101110	[10]
01000010	[11]
00000010	[12]
01010101	[13]
01001100	[14]
00111010	[15]

01001000	15	False
10000000	1	True
01111001	2	True
11011111	3	True
11101101	3	False
11100011	5	True
01100001	6	True
00110101	7	True
00010011	7	False
01110110	9	True
01101110	10	True
01000010	11	True
00000010	12	True
01010101	13	True
01001100	14	True
00111010	15	True

Number of codes used=16

Iteration=     70000 training nets give:
alice_loss.item()=0.007765225134789944	bob_loss.item()=0.0036300914362072945

10001000	[0]
11101000	[1]
01111001	[2]
10011111	[3]
11101101	[4]
11010011	[5]
01100001	[6]
01100011	[7]
01100000	[8]
01100010	[9]
01010111	[10]
00000110	[11]
00010010	[12]
00000100	[13]
01001100	[14]
00111010	[15]

10001000	0	True
11101000	1	True
01111001	2	True
10011111	1	False
11101101	4	True
11010011	5	True
01100001	6	True
01100011	7	True
01100000	8	True
01100010	9	True
01010111	10	True
00000110	11	True
00010010	13	False
00000100	13	True
01001100	14	True
00111010	15	True

Number of codes used=16



>>>> hp_run=4 of 4, time elapsed 1:02:16 of estimated 1:23:02, 
implying ending at 19:53:58BST on Saturday 8 May 2021
hyperparameters = {
	'N_ITERATIONS': 70000,
	'RANDOM_SEEDS': (14223, 244096, 596642, 487871),
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_LAYERS': 3,
	'BOB_WIDTH': 50,
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 2000,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 20000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_STRATEGY': 'circular_vocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': ('SGD', '{"lr": 0.01}'),
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': ('torch.nn.MSE', {}),
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0.3,
	'ALICE_DOUBLE': 500
}

tuple_specs.random_reward_sd()=0.7071067811865476

Iteration=     20000 training nets give:
alice_loss.item()=0.5582894682884216	bob_loss.item()=0.4414169192314148

01100001	[0, 1]
11100001	[2, 3]
01101001	[4, 5, 6, 7, 8, 9]
10111001	[10]
11010111	[11, 15]
10100000	[12, 13, 14]

01100001	6	False
11100001	15	False
01101001	8	True
10111001	13	False
11010111	15	True
10100000	15	False

Number of codes used=6

Iteration=     30000 training nets give:
alice_loss.item()=0.28535032272338867	bob_loss.item()=0.15084213018417358

11010111	[0, 15]
11100001	[1, 2]
01011010	[3, 4, 5, 6]
01101001	[7, 8, 9]
10111001	[10, 11, 12, 13]
10100000	[14]

11010111	15	True
11100001	2	True
01011010	6	True
01101001	7	True
10111001	11	True
10100000	15	False

Number of codes used=6

Iteration=     40000 training nets give:
alice_loss.item()=0.12015977501869202	bob_loss.item()=0.14713367819786072

10000001	[0]
11100001	[1]
11110001	[2, 3, 4]
01010010	[5]
01001001	[6]
11101001	[7]
11010101	[8]
10111000	[9]
00111001	[10]
10111001	[11]
10111101	[12]
11000011	[13]
10011101	[14]
11110011	[15]

10000001	1	False
11100001	2	False
11110001	1	False
01010010	5	True
01001001	8	False
11101001	7	True
11010101	15	False
10111000	11	False
00111001	10	True
10111001	11	True
10111101	11	False
11000011	15	False
10011101	11	False
11110011	15	True

Number of codes used=14

Iteration=     50000 training nets give:
alice_loss.item()=0.05873632803559303	bob_loss.item()=0.48853176832199097

11100100	[0]
10000011	[1]
00000001	[2]
01100010	[3]
11001000	[4]
01010010	[5]
11011011	[6]
11101001	[7]
00001101	[8]
00101000	[9]
10011000	[10]
00111100	[11]
10110010	[12]
10010101	[13]
00100000	[14]
10100010	[15]

11100100	0	True
10000011	1	True
00000001	5	False
01100010	3	True
11001000	4	True
01010010	5	True
11011011	6	True
11101001	6	False
00001101	8	True
00101000	9	True
10011000	10	True
00111100	10	False
10110010	12	True
10010101	13	True
00100000	14	True
10100010	14	False

Number of codes used=16

Iteration=     60000 training nets give:
alice_loss.item()=0.042081087827682495	bob_loss.item()=0.32407256960868835

11110111	[0, 15]
10000011	[1]
10001110	[2]
01100001	[3]
01110001	[4, 5]
01001000	[6]
01101001	[7]
00011001	[8]
10001001	[9]
10011011	[10]
10111111	[11]
11111101	[12]
10110000	[13]
00100000	[14]

11110111	15	True
10000011	0	False
10001110	12	False
01100001	3	True
01110001	5	True
01001000	5	False
01101001	7	True
00011001	8	True
10001001	9	True
10011011	9	False
10111111	11	True
11111101	9	False
10110000	13	True
00100000	14	True

Number of codes used=14

Iteration=     70000 training nets give:
alice_loss.item()=0.0018649855628609657	bob_loss.item()=0.003607090562582016

11000101	[0]
11100000	[1]
11100001	[2]
01100001	[3]
11001000	[4]
01001111	[5]
11011011	[6]
01111111	[7]
00011001	[8]
10001001	[9]
10001101	[10]
10111101	[11]
10101010	[12]
10010001	[13]
00100000	[14]
11010101	[15]

11000101	0	True
11100000	1	True
11100001	2	True
01100001	3	True
11001000	4	True
01001111	5	True
11011011	6	True
01111111	7	True
00011001	8	True
10001001	8	False
10001101	10	True
10111101	12	False
10101010	12	True
10010001	13	True
00100000	14	True
11010101	15	True

Number of codes used=16




Time taken over all 4 given sets of hyperparameters=1:23:13, averaging 0:20:48 per run


 ---- Table of results ----

  code  hp_run  result
 00000       1  (-0.901, 50000)
 00001       2  (-0.990, 70000)
 00002       3  (-0.972, 70000)
 00003       4  (-0.967, 70000)
 --------------------------

++++ Best result was (-0.990, 70000) on hp_run=2 with
hyperparameters = {
	'N_ITERATIONS': 70000,
	'RANDOM_SEEDS': (14223, 244096, 596642, 487871),
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_LAYERS': 3,
	'BOB_WIDTH': 50,
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 2000,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 20000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_STRATEGY': 'circular_vocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': ('SGD', '{"lr": 0.01}'),
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': ('torch.nn.MSE', {}),
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0.1,
	'ALICE_DOUBLE': 500
	'n_rng': Generator(PCG64)
	'ne_rng': Generator(PCG64)
	't_rng': <torch._C.Generator object at 0x7fd064ee8970>
	'te_rng': <torch._C.Generator object at 0x7fd064ee8a50>
}


End closed log for run 21-05-08_18:30:55BST
