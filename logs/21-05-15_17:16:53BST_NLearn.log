The closed log for run 21-05-15_17:16:53BST

SMOOTHING_LENGTH = 10000
SAVE_PERIOD = 100000
CODE_BOOK_PERIOD = 10000
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Used: "cuda"
MODEL_FOLDER = 'models'
CONFIGS_FOLDER = 'configs'
LOGS_FOLDER = 'logs'

hyperparameters = {
	'N_ITERATIONS': 35000,
	'RANDOM_SEEDS': [(714844, 936892, 888616, 165835)],
	'ALICE_NET': 'MaxNet("In", 3, 50)',
	'BOB_NET': 'FFs(3, 50)',
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 320000,
	'START_TRAINING': 10000,
	'N_SELECT': 256,
	'EPSILON_ONE_END': 1000.0,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 10000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_PLAY': 'CircularVocab',
	'BOB_TRAIN': 'CircularVocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': 'SGD(lr=0.01)',
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 15000,
	'NOISE': 0.1,
	'ALICE_DOUBLE': None,
	'N_CODE': 8,
	'N_NUMBERS': 256
}



>>>> hp_run=1 of 1
hyperparameters = {
	'N_ITERATIONS': 35000,
	'RANDOM_SEEDS': (714844, 936892, 888616, 165835),
	'ALICE_NET': 'MaxNet("In", 3, 50)',
	'BOB_NET': 'FFs(3, 50)',
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 320000,
	'START_TRAINING': 10000,
	'N_SELECT': 256,
	'EPSILON_ONE_END': 1000.0,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 10000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_PLAY': 'CircularVocab',
	'BOB_TRAIN': 'CircularVocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': 'SGD(lr=0.01)',
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 15000,
	'NOISE': 0.1,
	'ALICE_DOUBLE': None,
	'N_CODE': 8,
	'N_NUMBERS': 256
}

tuple_specs.random_reward_sd()=0.7071067811865476

Iteration=     10000 training nets give:
alice_loss.item()=0.5726343393325806	bob_loss.item()=0.5320597887039185

00110010	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]
01100111	[53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83]
00100011	[84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144]
10111101	[145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180]
10100011	[181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219]

00110010	31	True
01100111	43	False
00100011	39	False
10111101	42	False
10100011	247	False

Number of codes used=5

Iteration=     20000 training nets give:
alice_loss.item()=0.04743785411119461	bob_loss.item()=0.11310569941997528

00110000	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]
00110010	[17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
01100111	[41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]
11110111	[60, 61]
11100111	[62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]
11100011	[88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]
11000111	[99, 100, 101, 102, 103, 104, 105]
11101111	[106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130]
11001000	[131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]
11001001	[165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190]
11000001	[191, 192, 193, 194, 195, 196, 197, 198, 199]
11011001	[200, 201, 202, 203, 204, 205, 206]
10110011	[207, 208, 209, 210, 211, 212, 213, 214, 215, 216]
10100011	[217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241]

00110000	11	True
00110010	12	False
01100111	66	False
11110111	79	False
11100111	71	True
11100011	81	False
11000111	87	False
11101111	102	False
11001000	148	True
11001001	163	False
11000001	185	False
11011001	193	False
10110011	237	False
10100011	227	True

Number of codes used=14

Iteration=     30000 training nets give:
alice_loss.item()=0.030934689566493034	bob_loss.item()=0.040446944534778595

10110001	[0, 1, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]
01110000	[2, 3, 4, 5, 6, 7, 8]
00110010	[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
00010010	[25, 26, 27, 28, 29]
00110110	[30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]
01110111	[49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]
11100111	[67, 68, 69]
11100110	[70, 71, 72, 73, 74, 75]
10000111	[76, 77, 78, 79, 80, 81, 82, 83, 84, 85]
11000111	[86, 87, 88, 89, 90, 91, 92, 93, 94, 95]
11101111	[96, 97, 98]
11100101	[99, 100, 101, 102]
11001111	[103, 104, 105, 106, 107, 108, 109, 110]
10101101	[111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121]
01001001	[122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]
11001010	[133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146]
11001000	[147, 148, 149, 150, 151, 152]
10001001	[153, 154, 155, 156, 157, 158, 159, 160, 161]
11001001	[162, 163, 164, 165, 166, 167, 168, 169, 170, 171]
11101000	[172]
11000000	[173, 174, 175, 176, 177]
11000001	[178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]
10011001	[192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211]
10100001	[212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222]
10100011	[223, 224, 225, 226, 227, 228, 229, 230, 231, 232]
10100010	[233, 234, 235, 236, 237, 238, 239, 240]

10110001	243	True
01110000	6	True
00110010	15	True
00010010	21	False
00110110	38	True
01110111	53	True
11100111	63	False
11100110	67	False
10000111	74	False
11000111	83	False
11101111	82	False
11100101	102	True
11001111	105	True
10101101	115	True
01001001	133	False
11001010	142	True
11001000	158	False
10001001	163	False
11001001	168	True
11101000	163	False
11000000	168	False
11000001	191	True
10011001	197	True
10100001	220	True
10100011	229	True
10100010	232	False

Number of codes used=26


End of hp run 1.  Result of run:
[(-0.8680917336120645, 30000), ('21-05-15_17:16:53BST_NLearn_model_1_Alice_iter35000', '21-05-15_17:16:53BST_NLearn_model_1_Bob_iter35000')]
(-0.8680917336120645, 30000)



Time taken over all 1 given sets of hyperparameters=0:55:05, averaging 0:55:05 per run


 ---- Table of results ----

 code  hp_run  result
    0       1  (-0.868, 30000)
 --------------------------

++++ Best result was (-0.868, 30000) on hp_run=1 with
hyperparameters = {
	'N_ITERATIONS': 35000,
	'RANDOM_SEEDS': (714844, 936892, 888616, 165835),
	'ALICE_NET': 'MaxNet("In", 3, 50)',
	'BOB_NET': 'FFs(3, 50)',
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 320000,
	'START_TRAINING': 10000,
	'N_SELECT': 256,
	'EPSILON_ONE_END': 1000.0,
	'EPSILON_MIN': 0.0,
	'EPSILON_MIN_POINT': 10000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_PLAY': 'CircularVocab',
	'BOB_TRAIN': 'CircularVocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': 'SGD(lr=0.01)',
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 15000,
	'NOISE': 0.1,
	'ALICE_DOUBLE': None,
	'N_CODE': 8,
	'N_NUMBERS': 256
	'n_rng': Generator(PCG64)
	'ne_rng': Generator(PCG64)
	't_rng': <torch._C.Generator object at 0x7f68c7a2acf0>
	'te_rng': <torch._C.Generator object at 0x7f68c7a2a970>
}


End closed log for run 21-05-15_17:16:53BST
