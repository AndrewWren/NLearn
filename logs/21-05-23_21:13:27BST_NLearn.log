The closed log for run 21-05-23_21:13:27BST

SMOOTHING_LENGTH = 10000
SAVE_PERIOD = 100000
CODE_BOOK_PERIOD = 10000
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # Used: "cuda"
MODEL_FOLDER = 'models'
CONFIGS_FOLDER = 'configs'
LOGS_FOLDER = 'logs'

hyperparameters = {
	'N_ITERATIONS': 1000000,
	'RANDOM_SEEDS': [(532334, 809631, 735618, 545983), (321406, 416695, 885201, 467036)],
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_NET': 'FFs(3, 50)',
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 50000,
	'EPSILON_MIN': 0.01,
	'EPSILON_MIN_POINT': 600000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_PLAY': 'CircularVocab',
	'BOB_TRAIN': 'CircularVocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': 'SGD(lr=0.01)',
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0,
	'NOISE_END': 48000,
	'ALICE_DOUBLE': None,
	'N_CODE': 8,
	'NUMBERS': 'Basic',
	'N_NUMBERS': 16,
	'SHUFFLE': True,
	'REWARD_TYPE': 'Exact only'
}



>>>> hp_run=1 of 2
hyperparameters = {
	'N_ITERATIONS': 1000000,
	'RANDOM_SEEDS': (532334, 809631, 735618, 545983),
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_NET': 'FFs(3, 50)',
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 50000,
	'EPSILON_MIN': 0.01,
	'EPSILON_MIN_POINT': 600000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_PLAY': 'CircularVocab',
	'BOB_TRAIN': 'CircularVocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': 'SGD(lr=0.01)',
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0,
	'NOISE_END': 48000,
	'ALICE_DOUBLE': None,
	'N_CODE': 8,
	'NUMBERS': 'Basic',
	'N_NUMBERS': 16,
	'SHUFFLE': True,
	'REWARD_TYPE': 'Exact only'
}

0 away is reward of 1
1 or more away is reward of -0.06666666666666665
session_spec.random_reward_sd()=0.2581988897471611

Iteration=     10000 training nets give:
alice_loss=0	bob_loss=0

11110110	[0, 3, 6, 14]
10111101	[1, 2, 8, 10, 15]
10100110	[4, 9]
00110101	[5, 7, 13]
00001001	[11]
10110001	[12]

11110110	9		False
10111101	15		True
10100110	13		False
00110101	15		False
00001001	12		False
10110001	15		False

Number of codes used=6

Iteration=     20000 training nets give:
alice_loss=0.2621866464614868	bob_loss=0.0559767410159111

11110110	[0, 6, 14]
10111101	[1, 8, 10]
10111111	[2, 7]
10100110	[3, 4]
00001001	[5, 11]
00011110	[9, 15]
10110001	[12]
00110101	[13]

11110110	9		False
10111101	15		False
10111111	12		False
10100110	13		False
00001001	12		False
00011110	9		True
10110001	15		False
00110101	15		False

Number of codes used=8

Iteration=     30000 training nets give:
alice_loss=0.06302228569984436	bob_loss=0.06308688223361969

01001010	[0]
11001100	[1]
11101111	[2]
00001110	[3, 14]
10000011	[4]
01010001	[5, 15]
10000001	[6]
01100011	[7]
01000001	[8]
10001100	[9]
11010110	[10]
10100000	[11]
11010010	[12]
01100000	[13]

01001010	4		False
11001100	6		False
11101111	11		False
00001110	3		True
10000011	6		False
01010001	11		False
10000001	4		False
01100011	11		False
01000001	11		False
10001100	1		False
11010110	1		False
10100000	2		False
11010010	1		False
01100000	4		False

Number of codes used=14

Iteration=     40000 training nets give:
alice_loss=0.06341379880905151	bob_loss=0.06358426809310913

01001010	[0, 6]
11001100	[1]
11111110	[2, 8, 12]
00001110	[3]
01100111	[4]
00001001	[5]
10010101	[7]
00000011	[9]
11011001	[10, 11]
01010101	[13]
01010110	[14]
00001000	[15]

01001010	12		False
11001100	0		False
11111110	6		False
00001110	3		True
01100111	10		False
00001001	3		False
10010101	2		False
00000011	4		False
11011001	5		False
01010101	8		False
01010110	12		False
00001000	3		False

Number of codes used=12

Iteration=     50000 training nets give:
alice_loss=0.1263376772403717	bob_loss=0.12622195482254028

01001010	[0]
00001001	[1, 5, 10, 15]
00100110	[2]
10101001	[3, 14]
00000000	[4]
10001111	[6]
11101010	[7]
10000110	[8]
00000011	[9]
11011001	[11]
00111011	[12]
11110000	[13]

01001010	15		False
00001001	14		False
00100110	13		False
10101001	7		False
00000000	7		False
10001111	13		False
11101010	8		False
10000110	1		False
00000011	4		False
11011001	5		False
00111011	10		False
11110000	6		False

Number of codes used=12

Iteration=     60000 training nets give:
alice_loss=0.031569745391607285	bob_loss=0.03174858167767525

11000100	[0, 3, 14]
01101111	[1, 15]
00100110	[2]
00000000	[4, 5]
10001111	[6]
10010101	[7]
11111110	[8]
11011111	[9]
01000111	[10]
11010010	[11]
01010111	[12]
10000101	[13]

11000100	9		False
01101111	9		False
00100110	13		False
00000000	7		False
10001111	13		False
10010101	9		False
11111110	4		False
11011111	10		False
01000111	5		False
11010010	1		False
01010111	4		False
10000101	15		False

Number of codes used=12

Iteration=     70000 training nets give:
alice_loss=0.06336656957864761	bob_loss=0.0632801279425621

10011110	[0, 6, 8, 12]
01101111	[1]
00100110	[2]
11000001	[3]
11001000	[4, 5, 7, 11, 15]
10001011	[9]
11010000	[10]
10000101	[13]
11011010	[14]

10011110	10		False
01101111	12		False
00100110	13		False
11000001	9		False
11001000	10		False
10001011	6		False
11010000	0		False
10000101	14		False
11011010	12		False

Number of codes used=9

Iteration=     80000 training nets give:
alice_loss=0.03178902342915535	bob_loss=0.03174077719449997

00101110	[0, 10]
01101111	[1]
00100110	[2]
10101001	[3]
11011000	[4]
11111000	[5, 7, 9, 14, 15]
00111110	[6, 11]
10011110	[8, 12]
11110000	[13]

00101110	10		True
01101111	9		False
00100110	13		False
10101001	7		False
11011000	0		False
11111000	11		False
00111110	4		False
10011110	10		False
11110000	6		False

Number of codes used=9

Iteration=     90000 training nets give:
alice_loss=0.06330791115760803	bob_loss=0.06331297755241394

11010000	[0, 4, 5, 6, 7, 10, 11, 15]
11110000	[1, 13]
10001011	[2, 9]
00001110	[3, 14]
11000011	[8]
10100011	[12]

11010000	11		True
11110000	6		False
10001011	11		False
00001110	3		True
11000011	9		False
10100011	5		False

Number of codes used=6

Iteration=    100000 training nets give:
alice_loss=0.09496986865997314	bob_loss=0.09497888386249542

11011111	[0, 2, 5, 9, 11, 14]
01100000	[1, 13]
11000001	[3]
01100111	[4, 10]
01000001	[6]
00010011	[7]
11111110	[8, 12]
11111010	[15]

11011111	10		False
01100000	9		False
11000001	9		False
01100111	15		False
01000001	10		False
00010011	2		False
11111110	4		False
11111010	15		True

Number of codes used=8

Iteration=    110000 training nets give:
alice_loss=0.0635330006480217	bob_loss=0.06332187354564667

01000101	[0, 6, 8, 11, 12]
11110000	[1, 5, 13]
10001011	[2, 9]
10101001	[3, 14]
01100111	[4, 7, 10]
01000010	[15]

01000101	11		True
11110000	0		False
10001011	15		False
10101001	3		True
01100111	15		False
01000010	14		False

Number of codes used=6

Iteration=    120000 training nets give:
alice_loss=0.031928788870573044	bob_loss=0.03192051127552986

01101111	[0, 1, 13, 14]
00101000	[2, 6, 9, 11, 15]
11000001	[3]
01100111	[4, 5, 7, 8, 10]
01010101	[12]

01101111	9		False
00101000	6		True
11000001	12		False
01100111	10		True
01010101	10		False

Number of codes used=5

Iteration=    130000 training nets give:
alice_loss=0.09499718993902206	bob_loss=0.09486821293830872

10001111	[0, 1, 6, 7, 12]
00101101	[2, 9, 13]
00100010	[3]
01001110	[4, 10]
10000110	[5, 8]
00111010	[11]
01010110	[14]
01000010	[15]

10001111	13		False
00101101	13		True
00100010	8		False
01001110	7		False
10000110	13		False
00111010	10		False
01010110	13		False
01000010	5		False

Number of codes used=8

Iteration=    140000 training nets give:
alice_loss=0.09502821415662766	bob_loss=0.09491278231143951

01110000	[0, 5, 7]
11111001	[1]
10000011	[2, 3, 9, 13, 14]
11110001	[4]
01000101	[6, 8, 12]
01000111	[10]
01000011	[11]
11111010	[15]

01110000	1		False
11111001	9		False
10000011	15		False
11110001	9		False
01000101	15		False
01000111	7		False
01000011	1		False
11111010	15		True

Number of codes used=8

Iteration=    150000 training nets give:
alice_loss=0.06345009058713913	bob_loss=0.06334435939788818

00111111	[0]
11111001	[1, 5, 12, 14]
00100010	[2, 3]
11010010	[4, 10]
10011011	[6]
00011110	[7, 11]
01110001	[8]
10001011	[9]
11110000	[13]
11111010	[15]

00111111	9		False
11111001	4		False
00100010	8		False
11010010	15		False
10011011	10		False
00011110	2		False
01110001	15		False
10001011	1		False
11110000	4		False
11111010	9		False

Number of codes used=10

Iteration=    160000 training nets give:
alice_loss=0.03181462362408638	bob_loss=0.031872984021902084

00001000	[0, 5, 7, 13]
01010110	[1, 14]
10001011	[2, 3, 11, 15]
01100111	[4, 10]
11111110	[6, 8, 12]
10011111	[9]

00001000	13		True
01010110	5		False
10001011	9		False
01100111	2		False
11111110	8		True
10011111	15		False

Number of codes used=6

Iteration=    170000 training nets give:
alice_loss=0.0316862016916275	bob_loss=0.03189346194267273

00111111	[0]
00101101	[1, 2, 14]
00011110	[3, 7, 15]
01100111	[4, 10]
10011111	[5, 9]
01000101	[6, 11, 12]
11111111	[8, 13]

00111111	9		False
00101101	8		False
00011110	11		False
01100111	10		True
10011111	13		False
01000101	10		False
11111111	13		True

Number of codes used=7

Iteration=    180000 training nets give:
alice_loss=0.03178217634558678	bob_loss=0.031796496361494064

11111010	[0, 3, 6, 11, 13, 15]
10001111	[1, 10, 12]
10011111	[2, 9, 14]
11110011	[4, 5]
00011110	[7]
11000011	[8]

11111010	4		False
10001111	15		False
10011111	15		False
11110011	11		False
00011110	1		False
11000011	9		False

Number of codes used=6

Iteration=    190000 training nets give:
alice_loss=0.06334008276462555	bob_loss=0.06338632106781006

01100111	[0, 4, 5, 7, 8, 10, 11]
00100010	[1, 2, 3, 6, 13]
10011111	[9]
01000101	[12]
10000001	[14]
11111010	[15]

01100111	10		True
00100010	13		True
10011111	9		True
01000101	9		False
10000001	15		False
11111010	13		False

Number of codes used=6

Iteration=    200000 training nets give:
alice_loss=0.031788378953933716	bob_loss=0.0317784883081913

11111001	[0, 1, 5, 14]
11111111	[2, 13]
00110000	[3, 11]
01100111	[4, 7, 10]
01000001	[6, 8, 12]
01010110	[9]
11111010	[15]

11111001	6		False
11111111	0		False
00110000	9		False
01100111	10		True
01000001	9		False
01010110	9		True
11111010	14		False

Number of codes used=7

Iteration=    210000 training nets give:
alice_loss=0.09483063220977783	bob_loss=0.09488296508789062

10111111	[0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14]
00011011	[3]
00011110	[7, 15]
10011111	[9]

10111111	8		True
00011011	5		False
00011110	13		False
10011111	15		False

Number of codes used=4

Iteration=    220000 training nets give:
alice_loss=0.06332610547542572	bob_loss=0.06320331245660782

00001010	[0]
10111010	[1, 9, 10, 15]
00011011	[2, 3, 4, 5, 6, 7, 11, 13, 14]
00101010	[8]
10001111	[12]

00001010	10		False
10111010	1		True
00011011	9		False
00101010	1		False
10001111	4		False

Number of codes used=5

Iteration=    230000 training nets give:
alice_loss=0.22122083604335785	bob_loss=0.22147215902805328

11111110	[0]
01010110	[1]
00001110	[2, 3, 11, 13]
00001001	[4, 5, 7, 10, 14]
00010100	[6]
10111111	[8, 12]
11011111	[9]
10111010	[15]

11111110	8		False
01010110	9		False
00001110	12		False
00001001	5		True
00010100	14		False
10111111	8		True
11011111	12		False
10111010	1		False

Number of codes used=8

Iteration=    240000 training nets give:
alice_loss=0.06350105255842209	bob_loss=0.06314928829669952

00110101	[0, 1, 3, 4, 5, 8, 12, 14]
11010111	[2, 6]
10011100	[7]
00101101	[9]
00000000	[10, 11]
11110000	[13]
01000010	[15]

00110101	8		True
11010111	4		False
10011100	7		True
00101101	7		False
00000000	5		False
11110000	4		False
01000010	14		False

Number of codes used=7

Iteration=    250000 training nets give:
alice_loss=0.0633346289396286	bob_loss=0.06339246034622192

01100111	[0, 4, 7, 9, 10, 15]
10001001	[1, 2, 5, 11, 13, 14]
10001011	[3]
00001010	[6]
01110001	[8]
11111110	[12]

01100111	10		True
10001001	10		False
10001011	10		False
00001010	13		False
01110001	0		False
11111110	12		True

Number of codes used=6

Iteration=    260000 training nets give:
alice_loss=0.09473894536495209	bob_loss=0.09482768923044205

10011010	[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15]
10011111	[9]

10011010	3		True
10011111	15		False

Number of codes used=2

Iteration=    270000 training nets give:
alice_loss=0.18924540281295776	bob_loss=0.18940234184265137

00110101	[0, 14]
11011111	[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15]

00110101	15		False
11011111	4		True

Number of codes used=2

Iteration=    280000 training nets give:
alice_loss=0.1579894870519638	bob_loss=0.15815415978431702

00001010	[0, 6, 13, 14]
00111011	[1, 8]
10001011	[2, 3, 4, 5, 7, 9, 10, 11, 15]
11111110	[12]

00001010	13		True
00111011	10		False
10001011	10		True
11111110	12		True

Number of codes used=4

Iteration=    290000 training nets give:
alice_loss=0.031740836799144745	bob_loss=0.03121962584555149

01011000	[0, 2, 5, 7, 10, 11]
01011010	[1]
11111010	[3, 15]
11111110	[4, 9, 12]
11101101	[6]
11000100	[8, 14]
10101110	[13]

01011000	13		False
01011010	9		False
11111010	9		False
11111110	12		True
11101101	0		False
11000100	3		False
10101110	15		False

Number of codes used=7

Iteration=    300000 training nets give:
alice_loss=0.03186986222863197	bob_loss=0.03161028400063515

01100111	[0, 4, 5, 7, 10, 11]
01010011	[1, 13]
11101101	[2, 6, 9]
11111010	[3, 15]
01110001	[8]
11111110	[12]
11100001	[14]

01100111	10		True
01010011	8		False
11101101	0		False
11111010	12		False
01110001	3		False
11111110	12		True
11100001	0		False

Number of codes used=7

Iteration=    310000 training nets give:
alice_loss=0.1260456144809723	bob_loss=0.12649643421173096

01100111	[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15]
11101101	[6]

01100111	10		True
11101101	0		False

Number of codes used=2

Iteration=    320000 training nets give:
alice_loss=0.12661461532115936	bob_loss=0.1260295808315277

10100010	[0]
11010101	[1, 2, 6, 9, 12]
00001110	[3, 13, 14]
00101000	[4, 5]
00011110	[7, 8, 10, 11, 15]

10100010	15		False
11010101	10		False
00001110	11		False
00101000	6		False
00011110	6		False

Number of codes used=5

Iteration=    330000 training nets give:
alice_loss=0.12619146704673767	bob_loss=0.12586629390716553

10011100	[0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 14, 15]
11111110	[8, 9, 12, 13]

10011100	7		True
11111110	12		True

Number of codes used=2

Iteration=    340000 training nets give:
alice_loss=0.06345264613628387	bob_loss=0.06336964666843414

00110101	[0]
00111000	[1, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15]
10101001	[2]
11011111	[9, 12]

00110101	0		True
00111000	5		True
10101001	8		False
11011111	12		True

Number of codes used=4

Iteration=    350000 training nets give:
alice_loss=0.000781142502091825	bob_loss=0.0007906401879154146

10011111	[0, 2, 4, 5, 6, 7, 9, 11, 12, 13, 14]
01010011	[1, 8]
11111010	[3, 15]
10001100	[10]

10011111	11		True
01010011	6		False
11111010	12		False
10001100	15		False

Number of codes used=4

Iteration=    360000 training nets give:
alice_loss=0.09482333064079285	bob_loss=0.09385548532009125

00110101	[0, 14]
01010011	[1, 3, 15]
10100010	[2, 4, 5, 6, 8, 10, 11, 13]
10011100	[7]
10011111	[9, 12]

00110101	0		True
01010011	1		True
10100010	10		True
10011100	7		True
10011111	12		True

Number of codes used=5

Iteration=    370000 training nets give:
alice_loss=0.09459951519966125	bob_loss=0.09522159397602081

00101110	[0, 5, 6, 7, 8, 10, 11]
10001111	[1, 2, 14]
00011110	[3, 15]
11010010	[4, 9, 12]
00011011	[13]

00101110	11		True
10001111	1		True
00011110	1		False
11010010	3		False
00011011	5		False

Number of codes used=5

Iteration=    380000 training nets give:
alice_loss=0.03205044940114021	bob_loss=0.03177649527788162

00110101	[0, 13, 14]
11010010	[1, 2, 4, 5, 6, 7, 8, 9, 10, 11]
00111000	[3, 15]
10110010	[12]

00110101	0		True
11010010	14		False
00111000	15		True
10110010	14		False

Number of codes used=4

Iteration=    390000 training nets give:
alice_loss=0.06339377164840698	bob_loss=0.06353925168514252

11011111	[0, 4, 7, 9, 12]
00001010	[1, 2, 5, 6, 8, 10, 14, 15]
01010011	[3, 13]
10100000	[11]

11011111	12		True
00001010	7		False
01010011	4		False
10100000	11		True

Number of codes used=4

Iteration=    400000 training nets give:
alice_loss=0.15792278945446014	bob_loss=0.15744194388389587

11011111	[0, 4, 6, 7, 9, 12, 14]
10001011	[1, 2, 3, 10, 11, 13, 15]
00001001	[5, 8]

11011111	12		True
10001011	0		False
00001001	6		False

Number of codes used=3

Iteration=    410000 training nets give:
alice_loss=0.06358937919139862	bob_loss=0.06288833916187286

11110011	[0]
11000101	[1]
00101101	[2, 13]
11101010	[3, 6, 11, 14, 15]
11111110	[4, 12]
01001110	[5, 10]
00011110	[7, 8]
00100000	[9]

11110011	11		False
11000101	12		False
00101101	1		False
11101010	3		True
11111110	12		True
01001110	7		False
00011110	12		False
00100000	4		False

Number of codes used=8

Iteration=    420000 training nets give:
alice_loss=0.03207075223326683	bob_loss=0.033546991646289825

00100001	[0, 3, 4, 6, 7, 9, 11, 12, 14, 15]
10001000	[1, 8]
11001001	[2, 5, 10, 13]

00100001	14		True
10001000	5		False
11001001	3		False

Number of codes used=3

Iteration=    430000 training nets give:
alice_loss=0.06349939852952957	bob_loss=0.06358902901411057

11100001	[0, 14]
00001010	[1, 2, 8, 10]
00100000	[3, 4, 5, 7, 9, 11]
00101101	[6, 13]
10011111	[12]
00011011	[15]

11100001	14		True
00001010	13		False
00100000	3		True
00101101	5		False
10011111	4		False
00011011	13		False

Number of codes used=6

Iteration=    440000 training nets give:
alice_loss=0.09517880529165268	bob_loss=0.0948457270860672

01110110	[0, 7]
11101000	[1]
01001110	[2, 5, 8, 10, 11, 15]
10011111	[3, 4, 9, 12, 14]
01000001	[6, 13]

01110110	12		False
11101000	6		False
01001110	2		True
10011111	4		True
01000001	4		False

Number of codes used=5

Iteration=    450000 training nets give:
alice_loss=0.12611320614814758	bob_loss=0.12672512233257294

11000100	[0, 1, 5, 7, 8, 10, 13]
00101101	[2]
11100110	[3, 4, 12, 14]
00011011	[6, 11, 15]
00100000	[9]

11000100	4		False
00101101	8		False
11100110	4		True
00011011	8		False
00100000	4		False

Number of codes used=5

Iteration=    460000 training nets give:
alice_loss=0.031772010028362274	bob_loss=0.032097067683935165

10011100	[0, 7, 10]
01100001	[1, 6, 9, 13, 15]
00000011	[2]
10011111	[3, 4, 12, 14]
11001100	[5, 11]
11001000	[8]

10011100	7		True
01100001	14		False
00000011	6		False
10011111	12		True
11001100	5		True
11001000	8		True

Number of codes used=6

Iteration=    470000 training nets give:
alice_loss=0.15642718970775604	bob_loss=0.15697896480560303

11111110	[0, 3, 4, 9, 12]
01100001	[1]
00101011	[2, 6, 8, 10, 11]
10001010	[5, 7]
01010110	[13]
11100110	[14]
11010000	[15]

11111110	12		True
01100001	7		False
00101011	5		False
10001010	5		True
01010110	12		False
11100110	4		False
11010000	2		False

Number of codes used=7

Iteration=    480000 training nets give:
alice_loss=0.06356525421142578	bob_loss=0.06294044852256775

10011100	[0]
10001101	[1, 10, 15]
00001010	[2, 8]
11111010	[3, 14]
11111110	[4, 9]
00110101	[5]
11010111	[6, 11]
10001010	[7]
10011111	[12, 13]

10011100	7		False
10001101	10		True
00001010	5		False
11111010	3		True
11111110	12		False
00110101	0		False
11010111	12		False
10001010	0		False
10011111	12		True

Number of codes used=9

Iteration=    490000 training nets give:
alice_loss=0.09404069185256958	bob_loss=0.09398068487644196

00110101	[0, 2, 5, 6, 7, 8, 10, 11, 13]
01011010	[1]
01010110	[3, 4, 9, 14]
10011111	[12]
11010111	[15]

00110101	0		True
01011010	15		False
01010110	6		False
10011111	12		True
11010111	12		False

Number of codes used=5

Iteration=    500000 training nets give:
alice_loss=0.09441179782152176	bob_loss=0.09318743646144867

01000110	[0, 1, 2, 5, 6, 7, 8, 10, 11, 13]
11111010	[3]
00100001	[4, 9, 12, 14]
11000011	[15]

01000110	8		True
11111010	3		True
00100001	3		False
11000011	0		False

Number of codes used=4

Iteration=    510000 training nets give:
alice_loss=0.12405368685722351	bob_loss=0.1225268691778183

00100101	[0, 3, 4, 9, 12, 14]
00101101	[1, 2, 5, 6, 7, 8, 10, 13]
00000001	[11, 15]

00100101	14		True
00101101	13		True
00000001	0		False

Number of codes used=3

Iteration=    520000 training nets give:
alice_loss=0.12630552053451538	bob_loss=0.12734493613243103

11111010	[0, 3, 4, 12, 14]
01011000	[1, 5, 10, 11]
11000100	[2, 7, 8, 13]
10001101	[6, 9, 15]

11111010	3		True
01011000	5		True
11000100	8		True
10001101	13		False

Number of codes used=4

Iteration=    530000 training nets give:
alice_loss=0.06251811236143112	bob_loss=0.06263118982315063

00010010	[0, 2, 3, 4, 7, 8, 12, 14]
01100101	[1, 5, 6, 9, 11, 13]
11011011	[10]
11001011	[15]

00010010	2		True
01100101	14		False
11011011	14		False
11001011	3		False

Number of codes used=4

Iteration=    540000 training nets give:
alice_loss=0.09474698454141617	bob_loss=0.09622612595558167

11111001	[0, 1, 5]
11101010	[2, 8]
00010010	[3, 4]
11011001	[6, 9, 11, 15]
00000001	[7]
01000101	[10]
10001010	[12]
11101111	[13]
00000000	[14]

11111001	6		False
11101010	6		False
00010010	2		False
11011001	14		False
00000001	12		False
01000101	2		False
10001010	13		False
11101111	6		False
00000000	15		False

Number of codes used=9

Iteration=    550000 training nets give:
alice_loss=0.09518317878246307	bob_loss=0.09470941126346588

10011010	[0, 1, 5, 11]
00010010	[2, 3, 4, 8, 13]
00001010	[6]
10000111	[7, 14]
10001111	[9]
10100010	[10]
10010001	[12]
00111110	[15]

10011010	9		False
00010010	2		True
00001010	5		False
10000111	0		False
10001111	6		False
10100010	5		False
10010001	12		True
00111110	15		True

Number of codes used=8

Iteration=    560000 training nets give:
alice_loss=0.1266583502292633	bob_loss=0.12420311570167542

10100011	[0, 9, 13]
00100011	[1, 15]
11010010	[2, 4, 7, 8, 12]
11101111	[3]
11001001	[5]
00001010	[6]
11110011	[10]
10011010	[11]
10111010	[14]

10100011	9		True
00100011	8		False
11010010	8		True
11101111	6		False
11001001	8		False
00001010	8		False
11110011	3		False
10011010	12		False
10111010	6		False

Number of codes used=9

Iteration=    570000 training nets give:
alice_loss=0.09486759454011917	bob_loss=0.09363093972206116

10110111	[0]
00010101	[1, 5, 11, 13]
11010010	[2]
00010010	[3]
11001111	[4, 9, 14, 15]
00010001	[6]
00111101	[7]
11101010	[8]
00000000	[10]
01100111	[12]

10110111	9		False
00010101	13		True
11010010	6		False
00010010	4		False
11001111	7		False
00010001	9		False
00111101	8		False
11101010	3		False
00000000	8		False
01100111	1		False

Number of codes used=10

Iteration=    580000 training nets give:
alice_loss=0.25187358260154724	bob_loss=0.2498452067375183

01001010	[0, 6, 7, 13]
01101101	[1, 5, 10, 11, 15]
00101001	[2]
00110111	[3]
01100111	[4, 12]
11111110	[8]
10011100	[9]
10111010	[14]

01001010	2		False
01101101	11		True
00101001	2		True
00110111	0		False
01100111	2		False
11111110	12		False
10011100	7		False
10111010	15		False

Number of codes used=8

Iteration=    590000 training nets give:
alice_loss=0.18490837514400482	bob_loss=0.18391668796539307

11000110	[0, 1, 5, 6, 10, 11, 14, 15]
00110111	[2, 3, 4, 7, 8, 13]
11111110	[9, 12]

11000110	8		False
00110111	8		True
11111110	12		True

Number of codes used=3

Iteration=    600000 training nets give:
alice_loss=0.21656858921051025	bob_loss=0.2160017192363739

11001100	[0, 14]
10110010	[1, 8, 10, 15]
11111110	[2, 4, 9, 12]
00110110	[3]
00101010	[5]
00001010	[6]
00101001	[7]
11000110	[11, 13]

11001100	5		False
10110010	3		False
11111110	12		True
00110110	15		False
00101010	8		False
00001010	5		False
00101001	2		False
11000110	10		False

Number of codes used=8

Iteration=    610000 training nets give:
alice_loss=0.030824728310108185	bob_loss=0.03240539878606796

11001010	[0, 1]
10001111	[2]
10100001	[3, 15]
11111110	[4, 9, 12]
10011101	[5, 13]
00000010	[6, 7]
01110110	[8]
10001000	[10]
00110101	[11]
00101011	[14]

11001010	10		False
10001111	13		False
10100001	1		False
11111110	12		True
10011101	7		False
00000010	6		True
01110110	1		False
10001000	5		False
00110101	1		False
00101011	5		False

Number of codes used=10

Iteration=    620000 training nets give:
alice_loss=0.15232378244400024	bob_loss=0.15708865225315094

00111100	[0, 6, 14]
00010000	[1, 3, 15]
10001111	[2]
11111110	[4, 8, 9, 10, 11, 12]
01001100	[5]
10101110	[7, 13]

00111100	6		True
00010000	15		True
10001111	11		False
11111110	12		True
01001100	6		False
10101110	6		False

Number of codes used=6

Iteration=    630000 training nets give:
alice_loss=0.23437345027923584	bob_loss=0.25002697110176086

01001011	[0, 14]
00100010	[1, 13]
10001111	[2, 6, 7, 8]
10000000	[3]
10100000	[4, 15]
11010101	[5]
11111110	[9, 11, 12]
00101101	[10]

01001011	2		False
00100010	5		False
10001111	6		True
10000000	13		False
10100000	15		True
11010101	8		False
11111110	12		True
00101101	11		False

Number of codes used=8

Iteration=    640000 training nets give:
alice_loss=0.2723717987537384	bob_loss=0.2696292996406555

01000100	[0]
01110011	[1]
10001111	[2]
10010111	[3]
11111110	[4, 9, 12]
10110110	[5, 6, 11]
00111111	[7]
00001000	[8, 10]
00101100	[13]
10001000	[14]
10101110	[15]

01000100	8		False
01110011	1		True
10001111	6		False
10010111	2		False
11111110	12		True
10110110	1		False
00111111	11		False
00001000	0		False
00101100	15		False
10001000	10		False
10101110	6		False

Number of codes used=11

Iteration=    650000 training nets give:
alice_loss=0.12854504585266113	bob_loss=0.09882090985774994

10001111	[0, 6, 8, 11]
11111110	[1, 12]
00010001	[2, 7]
01110100	[3]
01010110	[4, 9]
01110101	[5, 13]
11110000	[10]
10001000	[14]
10101110	[15]

10001111	6		True
11111110	12		True
00010001	8		False
01110100	1		False
01010110	2		False
01110101	10		False
11110000	10		True
10001000	13		False
10101110	0		False

Number of codes used=9

Iteration=    660000 training nets give:
alice_loss=0.09413819015026093	bob_loss=0.11343728005886078

11111110	[0, 1, 12]
00110000	[2, 5, 8, 10, 13]
01100011	[3]
10001011	[4, 9]
10001111	[6, 11]
11000110	[7]
11101000	[14]
00111111	[15]

11111110	12		True
00110000	1		False
01100011	6		False
10001011	0		False
10001111	6		True
11000110	2		False
11101000	15		False
00111111	6		False

Number of codes used=8

Iteration=    670000 training nets give:
alice_loss=0.24519804120063782	bob_loss=0.1948176771402359

10001111	[0, 2, 6]
01010010	[1, 3, 14, 15]
01110111	[4]
01001000	[5]
00000101	[7, 13]
11010101	[8]
10100110	[9]
11111110	[10, 12]
00101101	[11]

10001111	11		False
01010010	10		False
01110111	10		False
01001000	8		False
00000101	11		False
11010101	2		False
10100110	15		False
11111110	12		True
00101101	11		True

Number of codes used=9

Iteration=    680000 training nets give:
alice_loss=0.22027957439422607	bob_loss=0.3080008625984192

10001111	[0, 2, 6, 10]
11111110	[1]
00010110	[3]
00011110	[4]
01010001	[5]
10110011	[7]
10001011	[8]
11110100	[9, 11]
10100110	[12]
00110101	[13]
01100000	[14]
00111100	[15]

10001111	6		True
11111110	12		False
00010110	13		False
00011110	7		False
01010001	2		False
10110011	10		False
10001011	0		False
11110100	10		False
10100110	9		False
00110101	1		False
01100000	1		False
00111100	6		False

Number of codes used=12

Iteration=    690000 training nets give:
alice_loss=0.004010176286101341	bob_loss=0.0714155063033104

11110100	[0, 11]
00001010	[1]
10001111	[2, 6, 12]
11100100	[3, 14]
00101010	[4]
01110011	[5]
11110101	[7]
00110000	[8]
01101101	[9]
11001001	[10]
01001010	[13]
01110001	[15]

11110100	4		False
00001010	11		False
10001111	6		True
11100100	0		False
00101010	11		False
01110011	8		False
11110101	1		False
00110000	15		False
01101101	5		False
11001001	9		False
01001010	8		False
01110001	12		False

Number of codes used=12

Iteration=    700000 training nets give:
alice_loss=0.09251042455434799	bob_loss=0.09400221705436707

11110100	[0, 6, 11]
01111010	[1]
01101101	[2, 9]
11100100	[3]
10001000	[4]
11110011	[5, 7]
00111000	[8]
01010011	[10, 13]
01000110	[12]
01111011	[14]
10000101	[15]

11110100	10		False
01111010	12		False
01101101	10		False
11100100	6		False
10001000	14		False
11110011	8		False
00111000	7		False
01010011	13		True
01000110	2		False
01111011	3		False
10000101	12		False

Number of codes used=11

Iteration=    710000 training nets give:
alice_loss=0.14333435893058777	bob_loss=0.0651821419596672

11110100	[0, 2, 6, 11]
11111110	[1, 3, 7, 13]
10110001	[4]
10110011	[5, 10, 15]
00110000	[8]
01001000	[9]
01010101	[12]
01111011	[14]

11110100	6		True
11111110	7		True
10110001	15		False
10110011	2		False
00110000	10		False
01001000	4		False
01010101	2		False
01111011	3		False

Number of codes used=8

Iteration=    720000 training nets give:
alice_loss=0.14178074896335602	bob_loss=0.19663836061954498

00111111	[0]
11111110	[1, 7, 13, 15]
11110100	[2, 3, 4, 6, 10, 12]
10110000	[5]
01010110	[8]
01110111	[9, 11]
01111011	[14]

00111111	13		False
11111110	1		True
11110100	6		True
10110000	4		False
01010110	7		False
01110111	13		False
01111011	3		False

Number of codes used=7

Iteration=    730000 training nets give:
alice_loss=0.06652946025133133	bob_loss=0.14598722755908966

10111110	[0, 11]
11111110	[1, 4]
01000110	[2, 5, 7, 8, 9, 12, 15]
10011001	[3, 13]
11110100	[6]
11110101	[10]
01011111	[14]

10111110	11		True
11111110	1		True
01000110	10		False
10011001	4		False
11110100	6		True
11110101	12		False
01011111	14		True

Number of codes used=7

Iteration=    740000 training nets give:
alice_loss=0.1546849012374878	bob_loss=0.23062869906425476

10000000	[0, 5, 14]
11111110	[1, 6, 10, 15]
11000110	[2]
00111100	[3, 4]
00001010	[7, 12, 13]
00110000	[8]
01111110	[9]
10111110	[11]

10000000	14		True
11111110	1		True
11000110	11		False
00111100	8		False
00001010	13		True
00110000	2		False
01111110	5		False
10111110	11		True

Number of codes used=8

Iteration=    750000 training nets give:
alice_loss=0.22765351831912994	bob_loss=0.1976461559534073

00010000	[0, 5]
11111110	[1]
01000100	[2, 8]
10001111	[3, 4, 7, 13]
10000000	[6]
00111111	[9, 10, 12, 15]
11110100	[11]
01101011	[14]

00010000	11		False
11111110	1		True
01000100	12		False
10001111	5		False
10000000	6		True
00111111	6		False
11110100	6		False
01101011	4		False

Number of codes used=8

Iteration=    760000 training nets give:
alice_loss=0.21208225190639496	bob_loss=0.16508197784423828

10101001	[0]
10000000	[1, 4]
10101100	[2]
00111110	[3]
00100110	[5]
01110111	[6, 10]
00000000	[7, 9]
10111000	[8]
01010101	[11]
01111100	[12]
01010111	[13]
10000010	[14]
01111001	[15]

10101001	13		False
10000000	6		False
10101100	11		False
00111110	13		False
00100110	6		False
01110111	6		True
00000000	1		False
10111000	11		False
01010101	4		False
01111100	1		False
01010111	5		False
10000010	14		True
01111001	10		False

Number of codes used=13

Iteration=    770000 training nets give:
alice_loss=0.12499453872442245	bob_loss=0.059223614633083344

00011011	[0, 11]
01110111	[1, 6]
01111100	[2, 3, 5, 8, 9, 12, 13, 15]
00010000	[4, 14]
10000110	[7]
10111101	[10]

00011011	11		True
01110111	6		True
01111100	8		True
00010000	5		False
10000110	8		False
10111101	5		False

Number of codes used=6

Iteration=    780000 training nets give:
alice_loss=0.1311766505241394	bob_loss=0.12680895626544952

00010101	[0, 5, 9, 14, 15]
00011011	[1, 11]
11111000	[2, 4, 13]
11001000	[3]
01110111	[6]
10000110	[7, 10, 12]
00000110	[8]

00010101	13		False
00011011	11		True
11111000	10		False
11001000	6		False
01110111	6		True
10000110	8		False
00000110	12		False

Number of codes used=7

Iteration=    790000 training nets give:
alice_loss=0.09284333884716034	bob_loss=0.06811903417110443

01100111	[0]
10011110	[1, 10]
11111110	[2, 8]
11110100	[3, 11, 14]
01111100	[4, 15]
00011011	[5]
10111110	[6]
00111000	[7, 13]
10001111	[9, 12]

01100111	10		False
10011110	11		False
11111110	11		False
11110100	8		False
01111100	7		False
00011011	5		True
10111110	6		True
00111000	1		False
10001111	13		False

Number of codes used=9

Iteration=    800000 training nets give:
alice_loss=0.09487120807170868	bob_loss=0.1298592984676361

01011010	[0, 5]
01000101	[1, 2, 3, 4, 7, 10, 12, 13]
10001111	[6, 11]
10010011	[8]
00100101	[9]
00100011	[14]
01101100	[15]

01011010	5		True
01000101	1		True
10001111	7		False
10010011	13		False
00100101	9		True
00100011	11		False
01101100	15		True

Number of codes used=7

Iteration=    810000 training nets give:
alice_loss=0.06400077790021896	bob_loss=0.0022596237249672413

10101000	[0, 1, 13]
00000000	[2]
10110111	[3, 12]
00000011	[4]
01011010	[5]
10010001	[6, 11]
10101111	[7]
11001111	[8]
11000011	[9, 15]
10011011	[10]
11010100	[14]

10101000	0		True
00000000	1		False
10110111	11		False
00000011	5		False
01011010	5		True
10010001	8		False
10101111	6		False
11001111	1		False
11000011	12		False
10011011	2		False
11010100	4		False

Number of codes used=11

Iteration=    820000 training nets give:
alice_loss=0.1265704482793808	bob_loss=0.06174596771597862

10000011	[0]
00000011	[1, 4, 7, 8, 10, 12]
11110100	[2, 14]
10110111	[3]
01011010	[5]
00000101	[6]
10001111	[9]
10010001	[11]
11111001	[13]
01101110	[15]

10000011	4		False
00000011	5		False
11110100	2		True
10110111	13		False
01011010	5		True
00000101	4		False
10001111	9		True
10010001	6		False
11111001	1		False
01101110	12		False

Number of codes used=10

Iteration=    830000 training nets give:
alice_loss=0.2800198793411255	bob_loss=0.19448009133338928

00100011	[0, 7, 8, 9, 10, 13, 15]
11110100	[1, 2, 5, 11, 12]
10110111	[3, 14]
00000011	[4]
00000101	[6]

00100011	0		True
11110100	2		True
10110111	3		True
00000011	4		True
00000101	6		True

Number of codes used=5

Iteration=    840000 training nets give:
alice_loss=0.1955292820930481	bob_loss=0.23642374575138092

10011011	[0, 1]
11110100	[2, 3]
01101110	[4, 9, 12, 14, 15]
10100101	[5, 13]
00000101	[6, 11]
01111100	[7, 8]
11110010	[10]

10011011	2		False
11110100	2		True
01101110	15		True
10100101	1		False
00000101	6		True
01111100	13		False
11110010	1		False

Number of codes used=7

Iteration=    850000 training nets give:
alice_loss=0.17914986610412598	bob_loss=0.17176762223243713

10100111	[0]
00010010	[1, 13, 15]
11110100	[2, 3]
11011001	[4]
11010100	[5]
11000101	[6, 11]
01111110	[7]
11101100	[8]
10100100	[9, 12]
00110011	[10]
01011010	[14]

10100111	11		False
00010010	7		False
11110100	2		True
11011001	2		False
11010100	3		False
11000101	9		False
01111110	6		False
11101100	3		False
10100100	0		False
00110011	10		True
01011010	11		False

Number of codes used=11

Iteration=    860000 training nets give:
alice_loss=0.10948679596185684	bob_loss=0.13910973072052002

11100011	[0, 13]
01010000	[1, 10]
10001111	[2]
11111110	[3]
10001101	[4, 14]
11110100	[5, 15]
11010100	[6]
11000110	[7, 8]
11000011	[9]
00100011	[11]
00101000	[12]

11100011	11		False
01010000	9		False
10001111	2		True
11111110	1		False
10001101	5		False
11110100	2		False
11010100	4		False
11000110	11		False
11000011	0		False
00100011	14		False
00101000	7		False

Number of codes used=11

Iteration=    870000 training nets give:
alice_loss=0.07518169283866882	bob_loss=0.07945869117975235

11110100	[0, 2, 5, 14]
01010111	[1]
10110110	[3]
11010101	[4, 6, 11]
10111000	[7]
11000110	[8]
00010110	[9, 12]
10111111	[10, 13]
01001110	[15]

11110100	4		False
01010111	11		False
10110110	1		False
11010101	3		False
10111000	6		False
11000110	11		False
00010110	0		False
10111111	10		True
01001110	10		False

Number of codes used=9

Iteration=    880000 training nets give:
alice_loss=0.0329289585351944	bob_loss=0.07112802565097809

10010111	[0]
11100110	[1, 10]
00011011	[2, 11]
11001111	[3]
11010101	[4, 6, 9, 15]
00010111	[5]
11101010	[7]
00101011	[8]
11100011	[12]
10010110	[13]
11110100	[14]

10010111	13		False
11100110	4		False
00011011	9		False
11001111	15		False
11010101	12		False
00010111	11		False
11101010	4		False
00101011	5		False
11100011	13		False
10010110	8		False
11110100	2		False

Number of codes used=11

Iteration=    890000 training nets give:
alice_loss=0.08117932826280594	bob_loss=0.0635451227426529

11010110	[0, 5, 14]
10001010	[1]
10001111	[2, 10]
10110110	[3, 9]
10011111	[4, 6]
01010010	[7]
01001110	[8]
00111110	[11]
10110111	[12, 15]
11110100	[13]

11010110	5		True
10001010	1		True
10001111	2		True
10110110	9		True
10011111	8		False
01010010	2		False
01001110	10		False
00111110	14		False
10110111	12		True
11110100	12		False

Number of codes used=10

Iteration=    900000 training nets give:
alice_loss=0.155164897441864	bob_loss=0.14628829061985016

10110001	[0]
11111110	[1, 9, 12, 15]
11010101	[2, 10]
11100110	[3, 4]
11110100	[5, 13, 14]
01110011	[6, 11]
01000101	[7]
10001100	[8]

10110001	10		False
11111110	9		True
11010101	4		False
11100110	4		True
11110100	14		True
01110011	8		False
01000101	12		False
10001100	8		True

Number of codes used=8

Iteration=    910000 training nets give:
alice_loss=0.21585693955421448	bob_loss=0.21327537298202515

01010100	[0]
11100110	[1, 2, 3, 4]
11010110	[5]
10110000	[6]
10001111	[7]
11001001	[8]
11111110	[9, 12, 15]
01010011	[10, 14]
01111011	[11]
11110100	[13]

01010100	2		False
11100110	4		True
11010110	7		False
10110000	1		False
10001111	2		False
11001001	11		False
11111110	9		True
01010011	5		False
01111011	1		False
11110100	14		False

Number of codes used=10

Iteration=    920000 training nets give:
alice_loss=0.17970269918441772	bob_loss=0.18466465175151825

11011011	[0, 5, 6, 8, 10, 13]
11100101	[1]
10000110	[2]
11110010	[3]
11010101	[4, 12]
00011101	[7]
11111110	[9, 14, 15]
10000111	[11]

11011011	5		True
11100101	3		False
10000110	2		True
11110010	15		False
11010101	4		True
00011101	12		False
11111110	9		True
10000111	14		False

Number of codes used=8

Iteration=    930000 training nets give:
alice_loss=0.0034880577586591244	bob_loss=0.017230529338121414

10110011	[0, 5]
00000011	[1]
11100111	[2, 8, 10, 13]
11110010	[3]
11011110	[4, 12, 15]
01111011	[6]
11110110	[7]
11111110	[9, 14]
10000111	[11]

10110011	5		True
00000011	4		False
11100111	10		True
11110010	15		False
11011110	9		False
01111011	6		True
11110110	5		False
11111110	9		True
10000111	14		False

Number of codes used=9

Iteration=    940000 training nets give:
alice_loss=0.12591654062271118	bob_loss=0.1268979012966156

11001100	[0, 3, 5, 6, 10]
00101001	[1]
11010010	[2]
11101101	[4, 8, 11]
00011101	[7]
10000111	[9]
11011110	[12]
11111110	[13, 14]
11110010	[15]

11001100	13		False
00101001	6		False
11010010	2		True
11101101	8		True
00011101	12		False
10000111	12		False
11011110	12		True
11111110	9		False
11110010	15		True

Number of codes used=9

Iteration=    950000 training nets give:
alice_loss=0.0640823096036911	bob_loss=0.06635955721139908

01101110	[0, 2, 11]
00110111	[1]
00000000	[3]
10000111	[4, 12]
11111110	[5, 6, 8, 9, 10, 13, 14]
11111001	[7]
00010111	[15]

01101110	1		False
00110111	10		False
00000000	0		False
10000111	12		True
11111110	9		True
11111001	3		False
00010111	5		False

Number of codes used=7

Iteration=    960000 training nets give:
alice_loss=0.05677265301346779	bob_loss=0.08285936713218689

01001110	[0, 2, 14]
01111100	[1]
00111110	[3, 4, 5, 7, 11]
11101001	[6]
10011100	[8]
11110010	[9]
11111110	[10]
11001101	[12]
00001001	[13, 15]

01001110	10		False
01111100	6		False
00111110	10		False
11101001	1		False
10011100	12		False
11110010	9		True
11111110	4		False
11001101	4		False
00001001	0		False

Number of codes used=9

Iteration=    970000 training nets give:
alice_loss=0.05299876630306244	bob_loss=0.03828635439276695

11100101	[0]
11111110	[1, 2, 3, 5, 6, 10, 13, 14]
00111100	[4]
01110110	[7, 9, 15]
11100111	[8]
11010010	[11]
10111110	[12]

11100101	2		False
11111110	13		True
00111100	7		False
01110110	9		True
11100111	15		False
11010010	2		False
10111110	8		False

Number of codes used=7

Iteration=    980000 training nets give:
alice_loss=0.037012211978435516	bob_loss=0.03353099524974823

10100011	[0, 14]
11100011	[1, 11]
00100100	[2, 8]
01111110	[3, 4, 5]
10001111	[6, 7, 10, 12]
00000001	[9]
11111110	[13]
11011101	[15]

10100011	0		True
11100011	1		True
00100100	2		True
01111110	13		False
10001111	2		False
00000001	9		True
11111110	13		True
11011101	15		True

Number of codes used=8

Iteration=    990000 training nets give:
alice_loss=0.09332667291164398	bob_loss=0.09603512287139893

11100000	[0, 1, 2, 4, 8, 10, 11, 14]
01011010	[3]
11010010	[5, 15]
10000000	[6]
11010101	[7, 12]
00001001	[9]
11111110	[13]

11100000	10		True
01011010	11		False
11010010	15		True
10000000	12		False
11010101	4		False
00001001	3		False
11111110	13		True

Number of codes used=7

Iteration=   1000000 training nets give:
alice_loss=0.18753394484519958	bob_loss=0.18945109844207764

10010101	[0, 3, 4, 6, 14]
01100011	[1, 2, 8, 10, 11]
11110010	[5, 13]
00001001	[7, 9, 15]
11100111	[12]

10010101	1		False
01100011	11		True
11110010	9		False
00001001	13		False
11100111	6		False

Number of codes used=5


End of hp run 1.  Result of run:
[(-0.18510939593034384, 740000), ('21-05-23_21:13:27BST_NLearn_model_1_Alice_iter1000000', '21-05-23_21:13:27BST_NLearn_model_1_Bob_iter1000000')]
(-0.18510939593034384, 740000)


>>>> hp_run=2 of 2, time elapsed 6:02:02 of estimated 12:04:05, 
implying ending at 09:17:31BST on Monday 24 May 2021
hyperparameters = {
	'N_ITERATIONS': 1000000,
	'RANDOM_SEEDS': (321406, 416695, 885201, 467036),
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_NET': 'FFs(3, 50)',
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 50000,
	'EPSILON_MIN': 0.01,
	'EPSILON_MIN_POINT': 600000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_PLAY': 'CircularVocab',
	'BOB_TRAIN': 'CircularVocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': 'SGD(lr=0.01)',
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0,
	'NOISE_END': 48000,
	'ALICE_DOUBLE': None,
	'N_CODE': 8,
	'NUMBERS': 'Basic',
	'N_NUMBERS': 16,
	'SHUFFLE': True,
	'REWARD_TYPE': 'Exact only'
}

0 away is reward of 1
1 or more away is reward of -0.06666666666666665
session_spec.random_reward_sd()=0.2581988897471611

Iteration=     10000 training nets give:
alice_loss=0	bob_loss=0

01101011	[0, 3, 5, 7, 8]
11011101	[1, 15]
01010111	[2, 6, 10, 11, 13, 14]
00110011	[4, 9]
10001010	[12]

01101011	14		False
11011101	11		False
01010111	13		True
00110011	15		False
10001010	5		False

Number of codes used=5

Iteration=     20000 training nets give:
alice_loss=0.2662706971168518	bob_loss=0.059131965041160583

01101011	[0, 3, 5, 7, 8]
11011101	[1, 15]
01010111	[2, 6, 10, 11, 13, 14]
00110011	[4, 9]
10001010	[12]

01101011	14		False
11011101	11		False
01010111	13		True
00110011	15		False
10001010	5		False

Number of codes used=5

Iteration=     30000 training nets give:
alice_loss=0.09488967806100845	bob_loss=0.09507624059915543

00101101	[0]
01011001	[1, 2]
11011010	[3]
01101001	[4]
01111101	[5]
00011101	[6]
00010111	[7]
10110010	[8]
11000000	[9]
10011001	[10]
00111100	[11]
00100010	[12]
00100100	[13]
10001001	[14]
01101010	[15]

00101101	5		False
01011001	13		False
11011010	13		False
01101001	3		False
01111101	6		False
00011101	4		False
00010111	15		False
10110010	11		False
11000000	11		False
10011001	7		False
00111100	2		False
00100010	1		False
00100100	15		False
10001001	5		False
01101010	4		False

Number of codes used=15

Iteration=     40000 training nets give:
alice_loss=0.06323477625846863	bob_loss=0.06345522403717041

11100111	[0]
00110001	[1, 5, 6, 7, 9, 10, 12, 15]
11010110	[2]
11100101	[3, 4, 11, 13, 14]
01010010	[8]

11100111	8		False
00110001	8		False
11010110	10		False
11100101	6		False
01010010	10		False

Number of codes used=5

Iteration=     50000 training nets give:
alice_loss=0.09487777948379517	bob_loss=0.09483727812767029

01000001	[0, 5, 6, 7, 9, 10, 12, 14]
11001111	[1, 2]
01001000	[3, 4, 11, 13]
01010010	[8]
01110101	[15]

01000001	13		False
11001111	3		False
01001000	11		True
01010010	10		False
01110101	3		False

Number of codes used=5

Iteration=     60000 training nets give:
alice_loss=0.09486784040927887	bob_loss=0.09479784965515137

11100111	[0, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14]
00100010	[1]
11011110	[2, 4, 8, 15]

11100111	8		False
00100010	1		True
11011110	0		False

Number of codes used=3

Iteration=     70000 training nets give:
alice_loss=0.12646475434303284	bob_loss=0.12662427127361298

10100000	[0, 14]
10000000	[1, 7, 10, 12]
10001000	[2]
00010011	[3, 4, 5, 6, 8, 9, 11, 13, 15]

10100000	13		False
10000000	11		False
10001000	14		False
00010011	5		True

Number of codes used=4

Iteration=     80000 training nets give:
alice_loss=0.09495191276073456	bob_loss=0.09492804110050201

01000000	[0, 12]
00111110	[1, 2, 3, 4, 5, 6, 7, 13]
01001101	[8, 9, 15]
01101010	[10]
00110000	[11]
00010010	[14]

01000000	0		True
00111110	2		True
01001101	0		False
01101010	3		False
00110000	8		False
00010010	15		False

Number of codes used=6

Iteration=     90000 training nets give:
alice_loss=0.0317331925034523	bob_loss=0.03179424628615379

00001110	[0, 7, 10, 12, 14]
10100111	[1, 3, 4, 5]
01010010	[2, 6, 8, 9, 11, 13, 15]

00001110	7		True
10100111	0		False
01010010	10		False

Number of codes used=3

Iteration=    100000 training nets give:
alice_loss=0.03177971765398979	bob_loss=0.03171458840370178

00100101	[0, 8, 9, 10, 14, 15]
00110011	[1, 2, 3, 4, 5, 6, 7, 11, 13]
00001011	[12]

00100101	10		True
00110011	2		True
00001011	8		False

Number of codes used=3

Iteration=    110000 training nets give:
alice_loss=0.12623144686222076	bob_loss=0.12650106847286224

00001110	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

00001110	7		True

Number of codes used=1

Iteration=    120000 training nets give:
alice_loss=0.0001936759945238009	bob_loss=0.00018585124053061008

00011101	[0, 7, 8, 9, 10, 14, 15]
11001000	[1, 3, 4, 5, 11, 12]
01011001	[2, 6, 13]

00011101	8		True
11001000	11		True
01011001	11		False

Number of codes used=3

Iteration=    130000 training nets give:
alice_loss=0.06332162022590637	bob_loss=0.06337468326091766

00110011	[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14]
00100100	[8, 15]
11101010	[12]

00110011	3		True
00100100	15		True
11101010	4		False

Number of codes used=3

Iteration=    140000 training nets give:
alice_loss=0.06333495676517487	bob_loss=0.06334636360406876

11101001	[0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 14, 15]
01001001	[6, 10, 13]
10100101	[12]

11101001	4		True
01001001	12		False
10100101	12		True

Number of codes used=3

Iteration=    150000 training nets give:
alice_loss=0.06330254673957825	bob_loss=0.06343555450439453

01001100	[0, 1, 2, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15]
11101001	[3, 4, 11]

01001100	0		True
11101001	4		True

Number of codes used=2

Iteration=    160000 training nets give:
alice_loss=0.09485170245170593	bob_loss=0.09481675177812576

10000010	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

10000010	11		True

Number of codes used=1

Iteration=    170000 training nets give:
alice_loss=0.06335766613483429	bob_loss=0.0633619874715805

11001000	[0, 1, 2, 3, 4, 5, 6, 7, 9, 11, 12, 13, 14]
01110001	[8, 10, 15]

11001000	3		True
01110001	9		False

Number of codes used=2

Iteration=    180000 training nets give:
alice_loss=0.06337464600801468	bob_loss=0.06332200765609741

00111010	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
11110111	[15]

00111010	14		True
11110111	10		False

Number of codes used=2

Iteration=    190000 training nets give:
alice_loss=0.06339605897665024	bob_loss=0.06334897875785828

10100101	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12]
01110001	[10, 13, 14, 15]

10100101	12		True
01110001	1		False

Number of codes used=2

Iteration=    200000 training nets give:
alice_loss=0.06335672736167908	bob_loss=0.06337365508079529

10100101	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14]
11011011	[10, 15]

10100101	12		True
11011011	14		False

Number of codes used=2

Iteration=    210000 training nets give:
alice_loss=0.031895581632852554	bob_loss=0.03181847557425499

00110011	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

00110011	1		True

Number of codes used=1

Iteration=    220000 training nets give:
alice_loss=0.031811583787202835	bob_loss=0.031817395240068436

00010011	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

00010011	2		True

Number of codes used=1

Iteration=    230000 training nets give:
alice_loss=0.03176882490515709	bob_loss=0.03178920969367027

01001100	[0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15]
11010110	[2, 4]
11001000	[11]

01001100	8		True
11010110	4		True
11001000	9		False

Number of codes used=3

Iteration=    240000 training nets give:
alice_loss=0.09478162229061127	bob_loss=0.09489485621452332

01010010	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

01010010	8		True

Number of codes used=1

Iteration=    250000 training nets give:
alice_loss=0.12659364938735962	bob_loss=0.12639901041984558

10110010	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

10110010	3		True

Number of codes used=1

Iteration=    260000 training nets give:
alice_loss=0.0317956805229187	bob_loss=0.031846802681684494

00111001	[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
10011110	[2]

00111001	15		True
10011110	1		False

Number of codes used=2

Iteration=    270000 training nets give:
alice_loss=0.06336458027362823	bob_loss=0.06335902214050293

01010010	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

01010010	8		True

Number of codes used=1

Iteration=    280000 training nets give:
alice_loss=0.06336504220962524	bob_loss=0.06345043331384659

00011101	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15]
11000101	[11]

00011101	11		False
11000101	14		False

Number of codes used=2

Iteration=    290000 training nets give:
alice_loss=0.031732089817523956	bob_loss=0.031798288226127625

10011010	[0, 1, 7, 8, 10, 14, 15]
01101001	[2, 3, 4, 5, 6, 9, 11, 12, 13]

10011010	4		False
01101001	2		True

Number of codes used=2

Iteration=    300000 training nets give:
alice_loss=0.06337045133113861	bob_loss=0.06335869431495667

10011110	[0, 1, 2, 5, 6, 7, 8, 10, 13, 15]
00111001	[3, 4, 9, 11, 14]
10100110	[12]

10011110	0		True
00111001	14		True
10100110	4		False

Number of codes used=3

Iteration=    310000 training nets give:
alice_loss=0.0317431278526783	bob_loss=0.03173299506306648

00101000	[0, 1, 3, 4, 5, 7, 8, 9, 10, 15]
01000010	[2, 6, 11, 12, 13, 14]

00101000	3		True
01000010	8		False

Number of codes used=2

Iteration=    320000 training nets give:
alice_loss=0.031789932399988174	bob_loss=0.031730059534311295

00010011	[0, 3, 7, 8]
01000010	[1, 2, 4, 5, 6, 9, 11, 12, 13]
01110001	[10, 14, 15]

00010011	15		False
01000010	11		True
01110001	11		False

Number of codes used=3

Iteration=    330000 training nets give:
alice_loss=0.06334899365901947	bob_loss=0.06333180516958237

01110001	[0, 10, 15]
01101001	[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14]

01110001	10		True
01101001	14		True

Number of codes used=2

Iteration=    340000 training nets give:
alice_loss=0.00021065297187305987	bob_loss=0.00025265413569286466

10001011	[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
01111011	[1, 15]

10001011	4		True
01111011	14		False

Number of codes used=2

Iteration=    350000 training nets give:
alice_loss=0.09483654797077179	bob_loss=0.09481678903102875

00010101	[0, 1, 2, 3, 4, 5, 6, 7, 9, 11, 12, 13, 14, 15]
01010010	[8]
01110001	[10]

00010101	3		True
01010010	13		False
01110001	10		True

Number of codes used=3

Iteration=    360000 training nets give:
alice_loss=0.06344127655029297	bob_loss=0.0635376125574112

00010101	[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

00010101	1		True

Number of codes used=1

Iteration=    370000 training nets give:
alice_loss=0.031806014478206635	bob_loss=0.03181561827659607

00010101	[0, 5, 6, 11, 13, 14]
01010010	[1, 2, 3, 4, 7, 8, 9, 10, 15]
01110001	[12]

00010101	10		False
01010010	8		True
01110001	10		False

Number of codes used=3

Iteration=    380000 training nets give:
alice_loss=0.157880961894989	bob_loss=0.15723702311515808

10001111	[0, 1, 2, 5, 6, 7, 10, 11, 12, 13, 14, 15]
01010010	[3, 4, 8, 9]

10001111	11		True
01010010	8		True

Number of codes used=2

Iteration=    390000 training nets give:
alice_loss=0.0632915124297142	bob_loss=0.0633423924446106

11011101	[0, 1]
01010010	[2, 3, 4, 8, 9, 15]
10100000	[5, 6, 7, 10, 11, 12, 13, 14]

11011101	1		True
01010010	8		True
10100000	7		True

Number of codes used=3

Iteration=    400000 training nets give:
alice_loss=0.09432084858417511	bob_loss=0.09396497905254364

10111001	[0, 3, 7, 11, 12, 14]
01010010	[1, 2, 4, 5, 6, 8, 10, 13, 15]
01011000	[9]

10111001	8		False
01010010	8		True
01011000	12		False

Number of codes used=3

Iteration=    410000 training nets give:
alice_loss=0.09494553506374359	bob_loss=0.09523038566112518

00010101	[0, 1, 2, 3, 5, 6, 7, 11, 12, 14]
01010010	[4, 8, 10, 13, 15]
01011000	[9]

00010101	13		False
01010010	8		True
01011000	12		False

Number of codes used=3

Iteration=    420000 training nets give:
alice_loss=0.09484988451004028	bob_loss=0.09506800770759583

10111001	[0, 1, 3, 5, 6, 7, 11, 12, 13, 14, 15]
01011000	[2, 9]
01010010	[4, 8, 10]

10111001	5		True
01011000	12		False
01010010	8		True

Number of codes used=3

Iteration=    430000 training nets give:
alice_loss=0.18910256028175354	bob_loss=0.18813636898994446

01110001	[0, 1, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15]
01010010	[4, 8]
01011000	[9]

01110001	10		True
01010010	8		True
01011000	2		False

Number of codes used=3

Iteration=    440000 training nets give:
alice_loss=0.09506803750991821	bob_loss=0.0949881374835968

01010010	[0, 1, 2, 3, 4, 5, 7, 8, 10, 15]
01110001	[6, 13]
01011000	[9]
10111001	[11, 14]
10000000	[12]

01010010	8		True
01110001	0		False
01011000	2		False
10111001	5		False
10000000	11		False

Number of codes used=5

Iteration=    450000 training nets give:
alice_loss=0.09346424043178558	bob_loss=0.09447561949491501

01010010	[0, 1, 2, 3, 4, 5, 7, 8, 15]
01110001	[6, 10, 11, 13]
01011000	[9]
10000000	[12]
10100000	[14]

01010010	8		True
01110001	0		False
01011000	1		False
10000000	11		False
10100000	11		False

Number of codes used=5

Iteration=    460000 training nets give:
alice_loss=0.0635245144367218	bob_loss=0.06376877427101135

10100000	[0, 1, 2, 5, 7, 10, 12, 13, 14, 15]
01010010	[3, 4, 8]
01001000	[6, 11]
01011000	[9]

10100000	11		False
01010010	8		True
01001000	5		False
01011000	15		False

Number of codes used=4

Iteration=    470000 training nets give:
alice_loss=0.09446082264184952	bob_loss=0.0947059914469719

00110111	[0, 3, 7]
10111001	[1, 2, 5, 6, 10, 11, 13, 14, 15]
01010010	[4, 8]
01011000	[9]
10110101	[12]

00110111	7		True
10111001	7		False
01010010	8		True
01011000	9		True
10110101	13		False

Number of codes used=5

Iteration=    480000 training nets give:
alice_loss=0.0942704826593399	bob_loss=0.09531456232070923

01110010	[0, 5, 7]
10110101	[1, 2, 6, 10, 11, 12, 13, 14, 15]
01010010	[3, 4, 8, 9]

01110010	0		True
10110101	11		True
01010010	8		True

Number of codes used=3

Iteration=    490000 training nets give:
alice_loss=0.1871863752603531	bob_loss=0.18719571828842163

01110010	[0, 2, 3, 5, 6, 7, 10, 11, 12, 13, 14]
10110101	[1]
01010010	[4, 8, 9]
01110001	[15]

01110010	0		True
10110101	6		False
01010010	8		True
01110001	15		True

Number of codes used=4

Iteration=    500000 training nets give:
alice_loss=0.06168266758322716	bob_loss=0.06510700285434723

01010010	[0, 4, 8]
10000000	[1, 3]
01110001	[2, 6, 10, 11, 13, 14, 15]
01011000	[5, 9]
00110111	[7]
00010011	[12]

01010010	8		True
10000000	13		False
01110001	15		True
01011000	9		True
00110111	1		False
00010011	3		False

Number of codes used=6

Iteration=    510000 training nets give:
alice_loss=0.0926380529999733	bob_loss=0.09400901198387146

00000111	[0, 5]
11001001	[1, 2, 6, 10, 11, 13, 15]
01101001	[3, 7]
10001000	[4]
01010010	[8]
01011000	[9]
10000000	[12]
01111011	[14]

00000111	5		True
11001001	12		False
01101001	11		False
10001000	6		False
01010010	8		True
01011000	9		True
10000000	11		False
01111011	7		False

Number of codes used=8

Iteration=    520000 training nets give:
alice_loss=0.0633229985833168	bob_loss=0.06349045038223267

10101011	[0]
00110111	[1]
00000101	[2, 6, 7, 14]
10110000	[3, 12]
01010010	[4, 8, 15]
01011000	[5, 9]
10100011	[10]
01111011	[11]
01110001	[13]

10101011	15		False
00110111	1		True
00000101	15		False
10110000	11		False
01010010	8		True
01011000	9		True
10100011	1		False
01111011	7		False
01110001	15		False

Number of codes used=9

Iteration=    530000 training nets give:
alice_loss=0.039930179715156555	bob_loss=0.03315873444080353

11010010	[0]
00110001	[1, 2, 6, 7, 10, 14]
10000110	[3]
01010010	[4, 8, 9, 13, 15]
00100100	[5, 11]
11011101	[12]

11010010	12		False
00110001	15		False
10000110	14		False
01010010	8		True
00100100	13		False
11011101	2		False

Number of codes used=6

Iteration=    540000 training nets give:
alice_loss=0.03316199779510498	bob_loss=0.033115681260824203

11000001	[0, 5, 15]
01010010	[1, 4, 8, 9, 10, 11, 13]
00110001	[2]
01101100	[3, 6, 7, 12, 14]

11000001	15		True
01010010	8		True
00110001	1		False
01101100	6		True

Number of codes used=4

Iteration=    550000 training nets give:
alice_loss=0.16990497708320618	bob_loss=0.18781839311122894

01010010	[0, 4, 8, 9, 11]
00101010	[1]
00001011	[2, 13, 14]
01110111	[3, 7]
11000001	[5, 15]
11100101	[6]
10011001	[10]
00111010	[12]

01010010	8		True
00101010	6		False
00001011	4		False
01110111	9		False
11000001	15		True
11100101	14		False
10011001	2		False
00111010	12		True

Number of codes used=8

Iteration=    560000 training nets give:
alice_loss=0.1850886344909668	bob_loss=0.175706684589386

01010010	[0, 4, 8, 9, 15]
00000101	[1, 2, 10, 14]
01000001	[3]
01100110	[5]
01100010	[6]
00000001	[7]
11011100	[11, 13]
00111010	[12]

01010010	8		True
00000101	10		True
01000001	13		False
01100110	2		False
01100010	10		False
00000001	10		False
11011100	6		False
00111010	12		True

Number of codes used=8

Iteration=    570000 training nets give:
alice_loss=0.15647001564502716	bob_loss=0.12735125422477722

01010010	[0, 1, 2, 4, 6, 8, 9, 10, 11, 12, 13]
10010000	[3, 5, 7]
10101111	[14, 15]

01010010	8		True
10010000	14		False
10101111	5		False

Number of codes used=3

Iteration=    580000 training nets give:
alice_loss=0.1265445053577423	bob_loss=0.12444032728672028

10010000	[0, 5, 7]
10111000	[1, 4, 12]
00000101	[2]
00111011	[3]
01000011	[6]
01010010	[8, 9, 13]
11101000	[10, 11, 14]
10100110	[15]

10010000	1		False
10111000	1		True
00000101	2		True
00111011	1		False
01000011	3		False
01010010	8		True
11101000	9		False
10100110	13		False

Number of codes used=8

Iteration=    590000 training nets give:
alice_loss=0.18570616841316223	bob_loss=0.18696142733097076

10101110	[0, 1, 3, 5, 6, 7, 11, 14, 15]
01010010	[2, 8, 13]
10111000	[4, 12]
01010110	[9, 10]

10101110	15		True
01010010	8		True
10111000	1		False
01010110	9		True

Number of codes used=4

Iteration=    600000 training nets give:
alice_loss=0.15163853764533997	bob_loss=0.15799261629581451

01001010	[0, 13, 14]
01010010	[1, 3, 15]
11100010	[2, 5, 10]
11010000	[4, 6, 7, 11, 12]
01010110	[8, 9]

01001010	5		False
01010010	8		False
11100010	3		False
11010000	3		False
01010110	9		True

Number of codes used=5

Iteration=    610000 training nets give:
alice_loss=0.050676360726356506	bob_loss=0.1256757378578186

00001110	[0]
01010010	[1, 13, 14]
00101001	[2, 5, 7, 10]
11010000	[3, 4, 12]
11101001	[6]
01010110	[8, 9]
00001000	[11]
10001010	[15]

00001110	1		False
01010010	8		False
00101001	6		False
11010000	7		False
11101001	0		False
01010110	9		True
00001000	14		False
10001010	14		False

Number of codes used=8

Iteration=    620000 training nets give:
alice_loss=0.018766848370432854	bob_loss=0.028996039181947708

11001000	[0]
01010010	[1, 13, 14]
10100111	[2, 6, 10, 11, 15]
10011010	[3, 4]
10111101	[5, 7, 8]
10111000	[9]
11010000	[12]

11001000	1		False
01010010	8		False
10100111	15		True
10011010	3		True
10111101	5		True
10111000	1		False
11010000	7		False

Number of codes used=7

Iteration=    630000 training nets give:
alice_loss=0.09522893279790878	bob_loss=0.09468262642621994

01000000	[0, 2, 7, 12, 15]
01010010	[1, 3, 5, 8, 11, 13, 14]
11101000	[4, 6, 10]
11010000	[9]

01000000	9		False
01010010	8		True
11101000	12		False
11010000	7		False

Number of codes used=4

Iteration=    640000 training nets give:
alice_loss=0.1886061429977417	bob_loss=0.18902838230133057

10001010	[0, 2, 7, 10, 15]
01010010	[1, 3, 5, 8, 14]
00111001	[4, 6]
11010000	[9, 11]
00111011	[12]
10000101	[13]

10001010	7		True
01010010	8		True
00111001	10		False
11010000	0		False
00111011	11		False
10000101	14		False

Number of codes used=6

Iteration=    650000 training nets give:
alice_loss=0.0937136709690094	bob_loss=0.09447473287582397

11100111	[0, 2, 5, 12, 13, 15]
01010010	[1, 4, 8, 14]
00001011	[3, 7, 10]
00111011	[6, 11]
01001010	[9]

11100111	5		True
01010010	8		True
00001011	3		True
00111011	6		True
01001010	5		False

Number of codes used=5

Iteration=    660000 training nets give:
alice_loss=0.10328446328639984	bob_loss=0.12587173283100128

10010110	[0, 2, 7]
01010010	[1, 4, 8, 10]
01000010	[3]
00100001	[5, 15]
10001001	[6, 11]
01001010	[9]
11100111	[12]
10011011	[13, 14]

10010110	8		False
01010010	8		True
01000010	8		False
00100001	5		True
10001001	7		False
01001010	8		False
11100111	5		False
10011011	12		False

Number of codes used=8

Iteration=    670000 training nets give:
alice_loss=0.06258326768875122	bob_loss=0.053294822573661804

00001111	[0, 7]
10111011	[1]
01000010	[2, 3, 4]
11011000	[5, 15]
01011010	[6, 10]
01010010	[8]
00111110	[9]
00100000	[11]
01000011	[12]
10011011	[13, 14]

00001111	11		False
10111011	9		False
01000010	8		False
11011000	7		False
01011010	6		True
01010010	8		True
00111110	9		True
00100000	6		False
01000011	4		False
10011011	12		False

Number of codes used=10

Iteration=    680000 training nets give:
alice_loss=0.06128742918372154	bob_loss=0.03304017707705498

10011111	[0]
01101100	[1]
10010010	[2, 7, 11]
11110101	[3]
01000010	[4]
01010010	[5, 8]
11011000	[6, 12, 15]
01000011	[9]
00111100	[10]
10100101	[13]
01011010	[14]

10011111	2		False
01101100	15		False
10010010	9		False
11110101	5		False
01000010	9		False
01010010	8		True
11011000	7		False
01000011	9		True
00111100	6		False
10100101	9		False
01011010	6		False

Number of codes used=11

Iteration=    690000 training nets give:
alice_loss=0.07212701439857483	bob_loss=0.09308309108018875

01010010	[0, 3, 5, 8, 11, 15]
10000011	[1, 7, 10, 13, 14]
00000011	[2, 12]
01000010	[4, 9]
10011101	[6]

01010010	8		True
10000011	8		False
00000011	3		False
01000010	9		True
10011101	0		False

Number of codes used=5

Iteration=    700000 training nets give:
alice_loss=0.028341155499219894	bob_loss=0.09368002414703369

01010010	[0, 8, 9, 10, 11, 13, 14, 15]
01001110	[1, 2, 5]
01101011	[3, 7]
11010101	[4, 12]
00001110	[6]

01010010	8		True
01001110	9		False
01101011	10		False
11010101	2		False
00001110	9		False

Number of codes used=5

Iteration=    710000 training nets give:
alice_loss=0.03555847331881523	bob_loss=0.06204851716756821

01010010	[0, 2, 8, 9, 15]
01001111	[1, 14]
00100101	[3, 4, 10]
11010101	[5, 13]
10010001	[6]
00001110	[7]
10100001	[11]
00110100	[12]

01010010	9		True
01001111	1		True
00100101	13		False
11010101	2		False
10010001	2		False
00001110	2		False
10100001	5		False
00110100	1		False

Number of codes used=8

Iteration=    720000 training nets give:
alice_loss=0.033533673733472824	bob_loss=0.03480412811040878

10001010	[0]
00110001	[1, 2, 10, 14]
01000111	[3]
10101100	[4]
10111110	[5, 13, 15]
00011011	[6]
11000000	[7]
11010000	[8]
10011101	[9]
01110110	[11]
11110011	[12]

10001010	7		False
00110001	7		False
01000111	15		False
10101100	4		True
10111110	3		False
00011011	6		True
11000000	7		True
11010000	3		False
10011101	0		False
01110110	7		False
11110011	3		False

Number of codes used=11

Iteration=    730000 training nets give:
alice_loss=0.03265732154250145	bob_loss=0.0333833247423172

01111001	[0, 5, 13, 14]
01001010	[1]
11110011	[2, 3, 7, 10, 12]
10101100	[4]
00011011	[6]
10111000	[8, 9]
11101000	[11]
11111010	[15]

01111001	6		False
01001010	10		False
11110011	3		True
10101100	4		True
00011011	6		True
10111000	2		False
11101000	12		False
11111010	8		False

Number of codes used=8

Iteration=    740000 training nets give:
alice_loss=0.12592864036560059	bob_loss=0.12514036893844604

01000011	[0]
10000001	[1, 2, 3, 7, 10, 12]
00110100	[4, 9]
01011010	[5, 15]
01010010	[6, 8]
01000010	[11, 13, 14]

01000011	8		False
10000001	4		False
00110100	2		False
01011010	11		False
01010010	11		False
01000010	8		False

Number of codes used=6

Iteration=    750000 training nets give:
alice_loss=0.15702959895133972	bob_loss=0.15665112435817719

00101010	[0]
11011100	[1, 10]
01010010	[2, 4, 5, 6, 8, 11, 13, 14]
01110101	[3, 7, 12]
10110000	[9]
00101101	[15]

00101010	0		True
11011100	13		False
01010010	11		True
01110101	3		True
10110000	2		False
00101101	6		False

Number of codes used=6

Iteration=    760000 training nets give:
alice_loss=0.09510023146867752	bob_loss=0.09448595345020294

11101111	[0]
11110111	[1, 2, 3, 5, 7, 10, 12, 14, 15]
01010010	[4, 6, 8, 11, 13]
01101100	[9]

11101111	5		False
11110111	2		True
01010010	11		True
01101100	4		False

Number of codes used=4

Iteration=    770000 training nets give:
alice_loss=0.1483311653137207	bob_loss=0.15163809061050415

10011111	[0, 7]
11111010	[1, 2, 5, 15]
01001111	[3, 4]
01000010	[6]
11010101	[8, 13]
01101100	[9, 12]
01010010	[10, 11]
01011010	[14]

10011111	10		False
11111010	8		False
01001111	2		False
01000010	8		False
11010101	5		False
01101100	4		False
01010010	11		True
01011010	11		False

Number of codes used=8

Iteration=    780000 training nets give:
alice_loss=0.20426851511001587	bob_loss=0.2157490849494934

01110110	[0, 5]
01110001	[1, 3, 4, 7, 9, 10]
01010010	[2, 6, 8, 11, 13, 15]
00011011	[12]
11010101	[14]

01110110	3		False
01110001	15		False
01010010	11		True
00011011	13		False
11010101	13		False

Number of codes used=5

Iteration=    790000 training nets give:
alice_loss=0.06285720318555832	bob_loss=0.0636267140507698

00010000	[0]
01001111	[1, 4, 8]
11011011	[2, 3, 12]
01110110	[5]
00000011	[6, 13]
01010010	[7, 11, 15]
11100111	[9]
00010010	[10]
00001000	[14]

00010000	2		False
01001111	1		True
11011011	15		False
01110110	1		False
00000011	3		False
01010010	11		True
11100111	1		False
00010010	6		False
00001000	15		False

Number of codes used=9

Iteration=    800000 training nets give:
alice_loss=0.1079946756362915	bob_loss=0.15615613758563995

00010000	[0]
01010010	[1, 11]
01110100	[2, 3, 5]
00000011	[4, 6, 8, 9, 13]
10011111	[7]
00011101	[10]
11011011	[12]
00010010	[14]
01011111	[15]

00010000	2		False
01010010	11		True
01110100	0		False
00000011	7		False
10011111	7		True
00011101	14		False
11011011	14		False
00010010	6		False
01011111	11		False

Number of codes used=9

Iteration=    810000 training nets give:
alice_loss=0.10497365146875381	bob_loss=0.15575051307678223

10011111	[0]
00000011	[1, 4, 7, 8, 9, 13]
10010100	[2, 5, 15]
00101111	[3, 10, 12]
01110100	[6]
01010010	[11]
11111001	[14]

10011111	7		False
00000011	8		True
10010100	2		True
00101111	9		False
01110100	7		False
01010010	11		True
11111001	1		False

Number of codes used=7

Iteration=    820000 training nets give:
alice_loss=0.09059125185012817	bob_loss=0.18593798577785492

01000100	[0, 3, 4, 5, 12]
11001011	[1, 2, 10, 14]
00101111	[6, 15]
01010010	[7, 8, 9, 11]
10010100	[13]

01000100	3		True
11001011	5		False
00101111	6		True
01010010	11		True
10010100	2		False

Number of codes used=5

Iteration=    830000 training nets give:
alice_loss=0.21343368291854858	bob_loss=0.2163538634777069

00100000	[0, 3, 9, 12, 14]
00000011	[1, 6, 7]
00101111	[2, 13]
01010010	[4, 5, 8, 10, 11, 15]

00100000	1		False
00000011	8		False
00101111	6		False
01010010	11		True

Number of codes used=4

Iteration=    840000 training nets give:
alice_loss=0.1068231388926506	bob_loss=0.12627415359020233

01101000	[0, 2, 3, 5, 7, 10, 14, 15]
10010001	[1, 13]
00000011	[4, 8, 9]
00101111	[6, 12]
01010010	[11]

01101000	1		False
10010001	13		True
00000011	8		True
00101111	6		True
01010010	11		True

Number of codes used=5

Iteration=    850000 training nets give:
alice_loss=0.18162395060062408	bob_loss=0.24883519113063812

00100000	[0, 3, 4, 5, 7, 10]
10010100	[1]
01010010	[2, 6, 11, 12]
00010010	[8]
11110000	[9]
11001100	[13]
01010110	[14]
00101111	[15]

00100000	15		False
10010100	1		True
01010010	11		True
00010010	10		False
11110000	9		True
11001100	12		False
01010110	10		False
00101111	6		False

Number of codes used=8

Iteration=    860000 training nets give:
alice_loss=0.09069477021694183	bob_loss=0.03664844110608101

01111000	[0]
01010110	[1, 2, 5, 13, 15]
11100011	[3, 4, 7]
11001100	[6, 12]
00000011	[8]
11110000	[9]
00101111	[10]
01010010	[11]
10111000	[14]

01111000	15		False
01010110	10		False
11100011	4		True
11001100	12		True
00000011	8		True
11110000	9		True
00101111	6		False
01010010	11		True
10111000	15		False

Number of codes used=9

Iteration=    870000 training nets give:
alice_loss=0.12902218103408813	bob_loss=0.12613898515701294

11100011	[0, 3, 7]
11001100	[1, 2, 4, 10]
10011010	[5, 15]
00101111	[6, 11]
01010010	[8]
00000011	[9, 12, 14]
00011100	[13]

11100011	4		False
11001100	12		False
10011010	3		False
00101111	6		True
01010010	11		False
00000011	8		False
00011100	3		False

Number of codes used=7

Iteration=    880000 training nets give:
alice_loss=0.08269380778074265	bob_loss=0.1251867562532425

00101111	[0, 4, 6, 7, 8, 11]
00001100	[1, 2, 3, 5, 9, 10, 15]
01010010	[12]
11101101	[13, 14]

00101111	6		True
00001100	3		True
01010010	11		False
11101101	4		False

Number of codes used=4

Iteration=    890000 training nets give:
alice_loss=0.054420106112957	bob_loss=0.034547604620456696

00000011	[0, 3, 7, 11, 15]
10010001	[1]
00111000	[2]
00010010	[4]
10010100	[5]
00101111	[6]
00110011	[8]
01010010	[9]
01101000	[10, 12]
11101011	[13]
10101111	[14]

00000011	12		False
10010001	13		False
00111000	10		False
00010010	10		False
10010100	12		False
00101111	11		False
00110011	5		False
01010010	11		False
01101000	1		False
11101011	14		False
10101111	6		False

Number of codes used=11

Iteration=    900000 training nets give:
alice_loss=0.1260964274406433	bob_loss=0.12519025802612305

00101111	[0]
10011111	[1, 3, 4, 8, 15]
10001101	[2, 9]
01010010	[5, 11]
11110001	[6, 12, 13, 14]
00000011	[7]
01101001	[10]

00101111	11		False
10011111	7		False
10001101	15		False
01010010	11		True
11110001	4		False
00000011	2		False
01101001	13		False

Number of codes used=7

Iteration=    910000 training nets give:
alice_loss=0.06151185557246208	bob_loss=0.062363795936107635

01011001	[0, 1, 2, 5, 7, 15]
01010010	[3, 4, 11, 13]
10001000	[6]
00001101	[8, 9]
11101011	[10, 12, 14]

01011001	13		False
01010010	11		True
10001000	12		False
00001101	5		False
11101011	14		True

Number of codes used=5

Iteration=    920000 training nets give:
alice_loss=0.17209824919700623	bob_loss=0.18722882866859436

00111110	[0]
00001011	[1, 2, 3, 4, 5, 7, 8, 9, 10, 15]
00001101	[6]
01010010	[11]
01100101	[12]
00101111	[13]
11001100	[14]

00111110	4		False
00001011	2		True
00001101	5		False
01010010	11		True
01100101	8		False
00101111	13		True
11001100	1		False

Number of codes used=7

Iteration=    930000 training nets give:
alice_loss=0.07459689676761627	bob_loss=0.12380841374397278

00101011	[0, 3, 5, 7]
01010010	[1, 4, 11]
01111111	[2, 8, 10, 15]
00110011	[6]
00001101	[9, 12]
00101101	[13]
10101110	[14]

00101011	15		False
01010010	11		True
01111111	14		False
00110011	5		False
00001101	5		False
00101101	13		True
10101110	1		False

Number of codes used=7

Iteration=    940000 training nets give:
alice_loss=0.030701441690325737	bob_loss=0.09444301575422287

00101011	[0, 6]
10101110	[1, 2, 3, 4, 7, 8, 13, 15]
01010010	[5, 9, 10, 11, 12, 14]

00101011	13		False
10101110	1		True
01010010	11		True

Number of codes used=3

Iteration=    950000 training nets give:
alice_loss=0.09270968288183212	bob_loss=0.15757633745670319

10110011	[0, 3, 5, 6, 7]
10101110	[1, 15]
00101100	[2]
00101011	[4, 8, 13]
01010010	[9, 10, 11, 12, 14]

10110011	15		False
10101110	15		True
00101100	1		False
00101011	13		True
01010010	11		True

Number of codes used=5

Iteration=    960000 training nets give:
alice_loss=0.03378641977906227	bob_loss=0.15752677619457245

10101110	[0, 7, 11]
00101100	[1, 3, 4, 8, 13]
10110011	[2, 5, 6]
01010010	[9, 10, 12, 14, 15]

10101110	15		False
00101100	3		True
10110011	0		False
01010010	11		False

Number of codes used=4

Iteration=    970000 training nets give:
alice_loss=0.12051962316036224	bob_loss=0.1255050152540207

10101110	[0, 3, 4, 5, 7]
00110011	[1, 8, 9, 12]
00101100	[2, 10]
01010010	[6, 11, 14, 15]
11110001	[13]

10101110	15		False
00110011	5		False
00101100	3		False
01010010	11		True
11110001	3		False

Number of codes used=5

Iteration=    980000 training nets give:
alice_loss=0.029762767255306244	bob_loss=0.031658709049224854

11010010	[0, 7]
01100001	[1, 8, 9, 12, 15]
01010001	[2, 4, 6]
01010010	[3, 5, 10, 11, 13, 14]

11010010	8		False
01100001	3		False
01010001	14		False
01010010	11		True

Number of codes used=4

Iteration=    990000 training nets give:
alice_loss=0.09630227833986282	bob_loss=0.18712393939495087

00011001	[0, 1, 2, 3, 4, 7, 12, 13]
01010010	[5, 8, 9, 10, 11, 14, 15]
01010001	[6]

00011001	11		False
01010010	11		True
01010001	14		False

Number of codes used=3

Iteration=   1000000 training nets give:
alice_loss=0.08199458569288254	bob_loss=0.06400644779205322

10101110	[0, 11]
00011001	[1, 3, 4, 7, 8]
01010010	[2, 5, 9, 10, 12, 14, 15]
00110011	[6, 13]

10101110	5		False
00011001	6		False
01010010	11		False
00110011	5		False

Number of codes used=4


End of hp run 2.  Result of run:
[(-0.17615590695381902, 850000), ('21-05-23_21:13:27BST_NLearn_model_2_Alice_iter1000000', '21-05-23_21:13:27BST_NLearn_model_2_Bob_iter1000000')]
(-0.17615590695381902, 850000)



Time taken over all 2 given sets of hyperparameters=12:02:20, averaging 6:01:10 per run


 ---- Table of results ----

 code  hp_run  result
    0       1  (-0.185, 740000)
    1       2  (-0.176, 850000)
 --------------------------

++++ Best result was (-0.185, 740000) on hp_run=1 with
hyperparameters = {
	'N_ITERATIONS': 1000000,
	'RANDOM_SEEDS': (532334, 809631, 735618, 545983),
	'ALICE_NET': 'FFs(3, 50)',
	'BOB_NET': 'FFs(3, 50)',
	'BATCHSIZE': 32,
	'GAMESIZE': 32,
	'BUFFER_CAPACITY': 640000,
	'START_TRAINING': 20000,
	'N_SELECT': 16,
	'EPSILON_ONE_END': 50000,
	'EPSILON_MIN': 0.01,
	'EPSILON_MIN_POINT': 600000,
	'ALICE_PLAY': 'QPerCode',
	'ALICE_TRAIN': 'QPerCode',
	'BOB_PLAY': 'CircularVocab',
	'BOB_TRAIN': 'CircularVocab',
	'ALICE_OPTIMIZER': 'SGD(lr=0.01)',
	'BOB_OPTIMIZER': 'SGD(lr=0.01)',
	'ALICE_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'BOB_LOSS_FUNCTION': 'Huber(beta=0.1)',
	'ALICE_PROXIMITY_BONUS': 100000000,
	'ALICE_PROXIMITY_SLOPE_LENGTH': 10000,
	'ALICE_LAST_TRAINING': 10000000,
	'NOISE_START': 30000,
	'NOISE': 0,
	'NOISE_END': 48000,
	'ALICE_DOUBLE': None,
	'N_CODE': 8,
	'NUMBERS': 'Basic',
	'N_NUMBERS': 16,
	'SHUFFLE': True,
	'REWARD_TYPE': 'Exact only'
	'n_rng': Generator(PCG64)
	'ne_rng': Generator(PCG64)
	't_rng': <torch._C.Generator object at 0x7f4de4350cf0>
	'te_rng': <torch._C.Generator object at 0x7f4de4350970>
}


End closed log for run 21-05-23_21:13:27BST
